

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">
  <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-6466750810172767"
     crossorigin="anonymous"></script>
  <script async src="https://fundingchoicesmessages.google.com/i/pub-6466750810172767?ers=1"></script><script>(function() {function signalGooglefcPresent() {if (!window.frames['googlefcPresent']) {if (document.body) {const iframe = document.createElement('iframe'); iframe.style = 'width: 0; height: 0; border: none; z-index: -1000; left: -1000px; top: -1000px;'; iframe.style.display = 'none'; iframe.name = 'googlefcPresent'; document.body.appendChild(iframe);} else {setTimeout(signalGooglefcPresent, 0);}}}signalGooglefcPresent();})();</script>
  <script>(function(){'use strict';function aa(a){var b=0;return function(){return b<a.length?{done:!1,value:a[b++]}:{done:!0}}}var ba=typeof Object.defineProperties=="function"?Object.defineProperty:function(a,b,c){if(a==Array.prototype||a==Object.prototype)return a;a[b]=c.value;return a};
function ca(a){a=["object"==typeof globalThis&&globalThis,a,"object"==typeof window&&window,"object"==typeof self&&self,"object"==typeof global&&global];for(var b=0;b<a.length;++b){var c=a[b];if(c&&c.Math==Math)return c}throw Error("Cannot find global object");}var da=ca(this);function l(a,b){if(b)a:{var c=da;a=a.split(".");for(var d=0;d<a.length-1;d++){var e=a[d];if(!(e in c))break a;c=c[e]}a=a[a.length-1];d=c[a];b=b(d);b!=d&&b!=null&&ba(c,a,{configurable:!0,writable:!0,value:b})}}
function ea(a){return a.raw=a}function n(a){var b=typeof Symbol!="undefined"&&Symbol.iterator&&a[Symbol.iterator];if(b)return b.call(a);if(typeof a.length=="number")return{next:aa(a)};throw Error(String(a)+" is not an iterable or ArrayLike");}function fa(a){for(var b,c=[];!(b=a.next()).done;)c.push(b.value);return c}var ha=typeof Object.create=="function"?Object.create:function(a){function b(){}b.prototype=a;return new b},p;
if(typeof Object.setPrototypeOf=="function")p=Object.setPrototypeOf;else{var q;a:{var ja={a:!0},ka={};try{ka.__proto__=ja;q=ka.a;break a}catch(a){}q=!1}p=q?function(a,b){a.__proto__=b;if(a.__proto__!==b)throw new TypeError(a+" is not extensible");return a}:null}var la=p;
function t(a,b){a.prototype=ha(b.prototype);a.prototype.constructor=a;if(la)la(a,b);else for(var c in b)if(c!="prototype")if(Object.defineProperties){var d=Object.getOwnPropertyDescriptor(b,c);d&&Object.defineProperty(a,c,d)}else a[c]=b[c];a.A=b.prototype}function ma(){for(var a=Number(this),b=[],c=a;c<arguments.length;c++)b[c-a]=arguments[c];return b}l("Object.is",function(a){return a?a:function(b,c){return b===c?b!==0||1/b===1/c:b!==b&&c!==c}});
l("Array.prototype.includes",function(a){return a?a:function(b,c){var d=this;d instanceof String&&(d=String(d));var e=d.length;c=c||0;for(c<0&&(c=Math.max(c+e,0));c<e;c++){var f=d[c];if(f===b||Object.is(f,b))return!0}return!1}});
l("String.prototype.includes",function(a){return a?a:function(b,c){if(this==null)throw new TypeError("The 'this' value for String.prototype.includes must not be null or undefined");if(b instanceof RegExp)throw new TypeError("First argument to String.prototype.includes must not be a regular expression");return this.indexOf(b,c||0)!==-1}});l("Number.MAX_SAFE_INTEGER",function(){return 9007199254740991});
l("Number.isFinite",function(a){return a?a:function(b){return typeof b!=="number"?!1:!isNaN(b)&&b!==Infinity&&b!==-Infinity}});l("Number.isInteger",function(a){return a?a:function(b){return Number.isFinite(b)?b===Math.floor(b):!1}});l("Number.isSafeInteger",function(a){return a?a:function(b){return Number.isInteger(b)&&Math.abs(b)<=Number.MAX_SAFE_INTEGER}});
l("Math.trunc",function(a){return a?a:function(b){b=Number(b);if(isNaN(b)||b===Infinity||b===-Infinity||b===0)return b;var c=Math.floor(Math.abs(b));return b<0?-c:c}});/*

 Copyright The Closure Library Authors.
 SPDX-License-Identifier: Apache-2.0
*/
var u=this||self;function v(a,b){a:{var c=["CLOSURE_FLAGS"];for(var d=u,e=0;e<c.length;e++)if(d=d[c[e]],d==null){c=null;break a}c=d}a=c&&c[a];return a!=null?a:b}function w(a){return a};function na(a){u.setTimeout(function(){throw a;},0)};var oa=v(610401301,!1),pa=v(188588736,!0),qa=v(645172343,v(1,!0));var x,ra=u.navigator;x=ra?ra.userAgentData||null:null;function z(a){return oa?x?x.brands.some(function(b){return(b=b.brand)&&b.indexOf(a)!=-1}):!1:!1}function A(a){var b;a:{if(b=u.navigator)if(b=b.userAgent)break a;b=""}return b.indexOf(a)!=-1};function B(){return oa?!!x&&x.brands.length>0:!1}function C(){return B()?z("Chromium"):(A("Chrome")||A("CriOS"))&&!(B()?0:A("Edge"))||A("Silk")};var sa=B()?!1:A("Trident")||A("MSIE");!A("Android")||C();C();A("Safari")&&(C()||(B()?0:A("Coast"))||(B()?0:A("Opera"))||(B()?0:A("Edge"))||(B()?z("Microsoft Edge"):A("Edg/"))||B()&&z("Opera"));var ta={},D=null;var ua=typeof Uint8Array!=="undefined",va=!sa&&typeof btoa==="function";var wa;function E(){return typeof BigInt==="function"};var F=typeof Symbol==="function"&&typeof Symbol()==="symbol";function xa(a){return typeof Symbol==="function"&&typeof Symbol()==="symbol"?Symbol():a}var G=xa(),ya=xa("2ex");var za=F?function(a,b){a[G]|=b}:function(a,b){a.g!==void 0?a.g|=b:Object.defineProperties(a,{g:{value:b,configurable:!0,writable:!0,enumerable:!1}})},H=F?function(a){return a[G]|0}:function(a){return a.g|0},I=F?function(a){return a[G]}:function(a){return a.g},J=F?function(a,b){a[G]=b}:function(a,b){a.g!==void 0?a.g=b:Object.defineProperties(a,{g:{value:b,configurable:!0,writable:!0,enumerable:!1}})};function Aa(a,b){J(b,(a|0)&-14591)}function Ba(a,b){J(b,(a|34)&-14557)};var K={},Ca={};function Da(a){return!(!a||typeof a!=="object"||a.g!==Ca)}function Ea(a){return a!==null&&typeof a==="object"&&!Array.isArray(a)&&a.constructor===Object}function L(a,b,c){if(!Array.isArray(a)||a.length)return!1;var d=H(a);if(d&1)return!0;if(!(b&&(Array.isArray(b)?b.includes(c):b.has(c))))return!1;J(a,d|1);return!0};var M=0,N=0;function Fa(a){var b=a>>>0;M=b;N=(a-b)/4294967296>>>0}function Ga(a){if(a<0){Fa(-a);var b=n(Ha(M,N));a=b.next().value;b=b.next().value;M=a>>>0;N=b>>>0}else Fa(a)}function Ia(a,b){b>>>=0;a>>>=0;if(b<=2097151)var c=""+(4294967296*b+a);else E()?c=""+(BigInt(b)<<BigInt(32)|BigInt(a)):(c=(a>>>24|b<<8)&16777215,b=b>>16&65535,a=(a&16777215)+c*6777216+b*6710656,c+=b*8147497,b*=2,a>=1E7&&(c+=a/1E7>>>0,a%=1E7),c>=1E7&&(b+=c/1E7>>>0,c%=1E7),c=b+Ja(c)+Ja(a));return c}
function Ja(a){a=String(a);return"0000000".slice(a.length)+a}function Ha(a,b){b=~b;a?a=~a+1:b+=1;return[a,b]};var Ka=/^-?([1-9][0-9]*|0)(\.[0-9]+)?$/;var O;function La(a,b){O=b;a=new a(b);O=void 0;return a}
function P(a,b,c){a==null&&(a=O);O=void 0;if(a==null){var d=96;c?(a=[c],d|=512):a=[];b&&(d=d&-16760833|(b&1023)<<14)}else{if(!Array.isArray(a))throw Error("narr");d=H(a);if(d&2048)throw Error("farr");if(d&64)return a;d|=64;if(c&&(d|=512,c!==a[0]))throw Error("mid");a:{c=a;var e=c.length;if(e){var f=e-1;if(Ea(c[f])){d|=256;b=f-(+!!(d&512)-1);if(b>=1024)throw Error("pvtlmt");d=d&-16760833|(b&1023)<<14;break a}}if(b){b=Math.max(b,e-(+!!(d&512)-1));if(b>1024)throw Error("spvt");d=d&-16760833|(b&1023)<<
14}}}J(a,d);return a};function Ma(a){switch(typeof a){case "number":return isFinite(a)?a:String(a);case "boolean":return a?1:0;case "object":if(a)if(Array.isArray(a)){if(L(a,void 0,0))return}else if(ua&&a!=null&&a instanceof Uint8Array){if(va){for(var b="",c=0,d=a.length-10240;c<d;)b+=String.fromCharCode.apply(null,a.subarray(c,c+=10240));b+=String.fromCharCode.apply(null,c?a.subarray(c):a);a=btoa(b)}else{b===void 0&&(b=0);if(!D){D={};c="ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789".split("");d=["+/=",
"+/","-_=","-_.","-_"];for(var e=0;e<5;e++){var f=c.concat(d[e].split(""));ta[e]=f;for(var g=0;g<f.length;g++){var h=f[g];D[h]===void 0&&(D[h]=g)}}}b=ta[b];c=Array(Math.floor(a.length/3));d=b[64]||"";for(e=f=0;f<a.length-2;f+=3){var k=a[f],m=a[f+1];h=a[f+2];g=b[k>>2];k=b[(k&3)<<4|m>>4];m=b[(m&15)<<2|h>>6];h=b[h&63];c[e++]=g+k+m+h}g=0;h=d;switch(a.length-f){case 2:g=a[f+1],h=b[(g&15)<<2]||d;case 1:a=a[f],c[e]=b[a>>2]+b[(a&3)<<4|g>>4]+h+d}a=c.join("")}return a}}return a};function Na(a,b,c){a=Array.prototype.slice.call(a);var d=a.length,e=b&256?a[d-1]:void 0;d+=e?-1:0;for(b=b&512?1:0;b<d;b++)a[b]=c(a[b]);if(e){b=a[b]={};for(var f in e)Object.prototype.hasOwnProperty.call(e,f)&&(b[f]=c(e[f]))}return a}function Oa(a,b,c,d,e){if(a!=null){if(Array.isArray(a))a=L(a,void 0,0)?void 0:e&&H(a)&2?a:Pa(a,b,c,d!==void 0,e);else if(Ea(a)){var f={},g;for(g in a)Object.prototype.hasOwnProperty.call(a,g)&&(f[g]=Oa(a[g],b,c,d,e));a=f}else a=b(a,d);return a}}
function Pa(a,b,c,d,e){var f=d||c?H(a):0;d=d?!!(f&32):void 0;a=Array.prototype.slice.call(a);for(var g=0;g<a.length;g++)a[g]=Oa(a[g],b,c,d,e);c&&c(f,a);return a}function Qa(a){return a.s===K?a.toJSON():Ma(a)};function Ra(a,b,c){c=c===void 0?Ba:c;if(a!=null){if(ua&&a instanceof Uint8Array)return b?a:new Uint8Array(a);if(Array.isArray(a)){var d=H(a);if(d&2)return a;b&&(b=d===0||!!(d&32)&&!(d&64||!(d&16)));return b?(J(a,(d|34)&-12293),a):Pa(a,Ra,d&4?Ba:c,!0,!0)}a.s===K&&(c=a.h,d=I(c),a=d&2?a:La(a.constructor,Sa(c,d,!0)));return a}}function Sa(a,b,c){var d=c||b&2?Ba:Aa,e=!!(b&32);a=Na(a,b,function(f){return Ra(f,e,d)});za(a,32|(c?2:0));return a};function Ta(a,b){a=a.h;return Ua(a,I(a),b)}function Va(a,b,c,d){b=d+(+!!(b&512)-1);if(!(b<0||b>=a.length||b>=c))return a[b]}
function Ua(a,b,c,d){if(c===-1)return null;var e=b>>14&1023||536870912;if(c>=e){if(b&256)return a[a.length-1][c]}else{var f=a.length;if(d&&b&256&&(d=a[f-1][c],d!=null)){if(Va(a,b,e,c)&&ya!=null){var g;a=(g=wa)!=null?g:wa={};g=a[ya]||0;g>=4||(a[ya]=g+1,g=Error(),g.__closure__error__context__984382||(g.__closure__error__context__984382={}),g.__closure__error__context__984382.severity="incident",na(g))}return d}return Va(a,b,e,c)}}
function Wa(a,b,c,d,e){var f=b>>14&1023||536870912;if(c>=f||e&&!qa){var g=b;if(b&256)e=a[a.length-1];else{if(d==null)return;e=a[f+(+!!(b&512)-1)]={};g|=256}e[c]=d;c<f&&(a[c+(+!!(b&512)-1)]=void 0);g!==b&&J(a,g)}else a[c+(+!!(b&512)-1)]=d,b&256&&(a=a[a.length-1],c in a&&delete a[c])}
function Xa(a,b){var c=Ya;var d=d===void 0?!1:d;var e=a.h;var f=I(e),g=Ua(e,f,b,d);if(g!=null&&typeof g==="object"&&g.s===K)c=g;else if(Array.isArray(g)){var h=H(g),k=h;k===0&&(k|=f&32);k|=f&2;k!==h&&J(g,k);c=new c(g)}else c=void 0;c!==g&&c!=null&&Wa(e,f,b,c,d);e=c;if(e==null)return e;a=a.h;f=I(a);f&2||(g=e,c=g.h,h=I(c),g=h&2?La(g.constructor,Sa(c,h,!1)):g,g!==e&&(e=g,Wa(a,f,b,e,d)));return e}function Za(a,b){a=Ta(a,b);return a==null||typeof a==="string"?a:void 0}
function $a(a,b){var c=c===void 0?0:c;a=Ta(a,b);if(a!=null)if(b=typeof a,b==="number"?Number.isFinite(a):b!=="string"?0:Ka.test(a))if(typeof a==="number"){if(a=Math.trunc(a),!Number.isSafeInteger(a)){Ga(a);b=M;var d=N;if(a=d&2147483648)b=~b+1>>>0,d=~d>>>0,b==0&&(d=d+1>>>0);b=d*4294967296+(b>>>0);a=a?-b:b}}else if(b=Math.trunc(Number(a)),Number.isSafeInteger(b))a=String(b);else{if(b=a.indexOf("."),b!==-1&&(a=a.substring(0,b)),!(a[0]==="-"?a.length<20||a.length===20&&Number(a.substring(0,7))>-922337:
a.length<19||a.length===19&&Number(a.substring(0,6))<922337)){if(a.length<16)Ga(Number(a));else if(E())a=BigInt(a),M=Number(a&BigInt(4294967295))>>>0,N=Number(a>>BigInt(32)&BigInt(4294967295));else{b=+(a[0]==="-");N=M=0;d=a.length;for(var e=b,f=(d-b)%6+b;f<=d;e=f,f+=6)e=Number(a.slice(e,f)),N*=1E6,M=M*1E6+e,M>=4294967296&&(N+=Math.trunc(M/4294967296),N>>>=0,M>>>=0);b&&(b=n(Ha(M,N)),a=b.next().value,b=b.next().value,M=a,N=b)}a=M;b=N;b&2147483648?E()?a=""+(BigInt(b|0)<<BigInt(32)|BigInt(a>>>0)):(b=
n(Ha(a,b)),a=b.next().value,b=b.next().value,a="-"+Ia(a,b)):a=Ia(a,b)}}else a=void 0;return a!=null?a:c}function R(a,b){var c=c===void 0?"":c;a=Za(a,b);return a!=null?a:c};var S;function T(a,b,c){this.h=P(a,b,c)}T.prototype.toJSON=function(){return ab(this)};T.prototype.s=K;T.prototype.toString=function(){try{return S=!0,ab(this).toString()}finally{S=!1}};
function ab(a){var b=S?a.h:Pa(a.h,Qa,void 0,void 0,!1);var c=!S;var d=pa?void 0:a.constructor.v;var e=I(c?a.h:b);if(a=b.length){var f=b[a-1],g=Ea(f);g?a--:f=void 0;e=+!!(e&512)-1;var h=b;if(g){b:{var k=f;var m={};g=!1;if(k)for(var r in k)if(Object.prototype.hasOwnProperty.call(k,r))if(isNaN(+r))m[r]=k[r];else{var y=k[r];Array.isArray(y)&&(L(y,d,+r)||Da(y)&&y.size===0)&&(y=null);y==null&&(g=!0);y!=null&&(m[r]=y)}if(g){for(var Q in m)break b;m=null}else m=k}k=m==null?f!=null:m!==f}for(var ia;a>0;a--){Q=
a-1;r=h[Q];Q-=e;if(!(r==null||L(r,d,Q)||Da(r)&&r.size===0))break;ia=!0}if(h!==b||k||ia){if(!c)h=Array.prototype.slice.call(h,0,a);else if(ia||k||m)h.length=a;m&&h.push(m)}b=h}return b};function bb(a){return function(b){if(b==null||b=="")b=new a;else{b=JSON.parse(b);if(!Array.isArray(b))throw Error("dnarr");za(b,32);b=La(a,b)}return b}};function cb(a){this.h=P(a)}t(cb,T);var db=bb(cb);var U;function V(a){this.g=a}V.prototype.toString=function(){return this.g+""};var eb={};function fb(a){if(U===void 0){var b=null;var c=u.trustedTypes;if(c&&c.createPolicy){try{b=c.createPolicy("goog#html",{createHTML:w,createScript:w,createScriptURL:w})}catch(d){u.console&&u.console.error(d.message)}U=b}else U=b}a=(b=U)?b.createScriptURL(a):a;return new V(a,eb)};/*

 SPDX-License-Identifier: Apache-2.0
*/
function gb(a){var b=ma.apply(1,arguments);if(b.length===0)return fb(a[0]);for(var c=a[0],d=0;d<b.length;d++)c+=encodeURIComponent(b[d])+a[d+1];return fb(c)};function hb(a,b){a.src=b instanceof V&&b.constructor===V?b.g:"type_error:TrustedResourceUrl";var c,d;(c=(b=(d=(c=(a.ownerDocument&&a.ownerDocument.defaultView||window).document).querySelector)==null?void 0:d.call(c,"script[nonce]"))?b.nonce||b.getAttribute("nonce")||"":"")&&a.setAttribute("nonce",c)};function ib(){return Math.floor(Math.random()*2147483648).toString(36)+Math.abs(Math.floor(Math.random()*2147483648)^Date.now()).toString(36)};function jb(a,b){b=String(b);a.contentType==="application/xhtml+xml"&&(b=b.toLowerCase());return a.createElement(b)}function kb(a){this.g=a||u.document||document};function lb(a){a=a===void 0?document:a;return a.createElement("script")};function mb(a,b,c,d,e,f){try{var g=a.g,h=lb(g);h.async=!0;hb(h,b);g.head.appendChild(h);h.addEventListener("load",function(){e();d&&g.head.removeChild(h)});h.addEventListener("error",function(){c>0?mb(a,b,c-1,d,e,f):(d&&g.head.removeChild(h),f())})}catch(k){f()}};var nb=u.atob("aHR0cHM6Ly93d3cuZ3N0YXRpYy5jb20vaW1hZ2VzL2ljb25zL21hdGVyaWFsL3N5c3RlbS8xeC93YXJuaW5nX2FtYmVyXzI0ZHAucG5n"),ob=u.atob("WW91IGFyZSBzZWVpbmcgdGhpcyBtZXNzYWdlIGJlY2F1c2UgYWQgb3Igc2NyaXB0IGJsb2NraW5nIHNvZnR3YXJlIGlzIGludGVyZmVyaW5nIHdpdGggdGhpcyBwYWdlLg=="),pb=u.atob("RGlzYWJsZSBhbnkgYWQgb3Igc2NyaXB0IGJsb2NraW5nIHNvZnR3YXJlLCB0aGVuIHJlbG9hZCB0aGlzIHBhZ2Uu");function qb(a,b,c){this.i=a;this.u=b;this.o=c;this.g=null;this.j=[];this.m=!1;this.l=new kb(this.i)}
function rb(a){if(a.i.body&&!a.m){var b=function(){sb(a);u.setTimeout(function(){tb(a,3)},50)};mb(a.l,a.u,2,!0,function(){u[a.o]||b()},b);a.m=!0}}
function sb(a){for(var b=W(1,5),c=0;c<b;c++){var d=X(a);a.i.body.appendChild(d);a.j.push(d)}b=X(a);b.style.bottom="0";b.style.left="0";b.style.position="fixed";b.style.width=W(100,110).toString()+"%";b.style.zIndex=W(2147483544,2147483644).toString();b.style.backgroundColor=ub(249,259,242,252,219,229);b.style.boxShadow="0 0 12px #888";b.style.color=ub(0,10,0,10,0,10);b.style.display="flex";b.style.justifyContent="center";b.style.fontFamily="Roboto, Arial";c=X(a);c.style.width=W(80,85).toString()+
"%";c.style.maxWidth=W(750,775).toString()+"px";c.style.margin="24px";c.style.display="flex";c.style.alignItems="flex-start";c.style.justifyContent="center";d=jb(a.l.g,"IMG");d.className=ib();d.src=nb;d.alt="Warning icon";d.style.height="24px";d.style.width="24px";d.style.paddingRight="16px";var e=X(a),f=X(a);f.style.fontWeight="bold";f.textContent=ob;var g=X(a);g.textContent=pb;Y(a,e,f);Y(a,e,g);Y(a,c,d);Y(a,c,e);Y(a,b,c);a.g=b;a.i.body.appendChild(a.g);b=W(1,5);for(c=0;c<b;c++)d=X(a),a.i.body.appendChild(d),
a.j.push(d)}function Y(a,b,c){for(var d=W(1,5),e=0;e<d;e++){var f=X(a);b.appendChild(f)}b.appendChild(c);c=W(1,5);for(d=0;d<c;d++)e=X(a),b.appendChild(e)}function W(a,b){return Math.floor(a+Math.random()*(b-a))}function ub(a,b,c,d,e,f){return"rgb("+W(Math.max(a,0),Math.min(b,255)).toString()+","+W(Math.max(c,0),Math.min(d,255)).toString()+","+W(Math.max(e,0),Math.min(f,255)).toString()+")"}function X(a){a=jb(a.l.g,"DIV");a.className=ib();return a}
function tb(a,b){b<=0||a.g!=null&&a.g.offsetHeight!==0&&a.g.offsetWidth!==0||(vb(a),sb(a),u.setTimeout(function(){tb(a,b-1)},50))}function vb(a){for(var b=n(a.j),c=b.next();!c.done;c=b.next())(c=c.value)&&c.parentNode&&c.parentNode.removeChild(c);a.j=[];(b=a.g)&&b.parentNode&&b.parentNode.removeChild(b);a.g=null};function wb(a,b,c,d,e){function f(k){document.body?g(document.body):k>0?u.setTimeout(function(){f(k-1)},e):b()}function g(k){k.appendChild(h);u.setTimeout(function(){h?(h.offsetHeight!==0&&h.offsetWidth!==0?b():a(),h.parentNode&&h.parentNode.removeChild(h)):a()},d)}var h=xb(c);f(3)}function xb(a){var b=document.createElement("div");b.className=a;b.style.width="1px";b.style.height="1px";b.style.position="absolute";b.style.left="-10000px";b.style.top="-10000px";b.style.zIndex="-10000";return b};function Ya(a){this.h=P(a)}t(Ya,T);function yb(a){this.h=P(a)}t(yb,T);var zb=bb(yb);function Ab(a){if(!a)return null;a=Za(a,4);var b;a===null||a===void 0?b=null:b=fb(a);return b};var Bb=ea([""]),Cb=ea([""]);function Db(a,b){this.m=a;this.o=new kb(a.document);this.g=b;this.j=R(this.g,1);this.u=Ab(Xa(this.g,2))||gb(Bb);this.i=!1;b=Ab(Xa(this.g,13))||gb(Cb);this.l=new qb(a.document,b,R(this.g,12))}Db.prototype.start=function(){Eb(this)};
function Eb(a){Fb(a);mb(a.o,a.u,3,!1,function(){a:{var b=a.j;var c=u.btoa(b);if(c=u[c]){try{var d=db(u.atob(c))}catch(e){b=!1;break a}b=b===Za(d,1)}else b=!1}b?Z(a,R(a.g,14)):(Z(a,R(a.g,8)),rb(a.l))},function(){wb(function(){Z(a,R(a.g,7));rb(a.l)},function(){return Z(a,R(a.g,6))},R(a.g,9),$a(a.g,10),$a(a.g,11))})}function Z(a,b){a.i||(a.i=!0,a=new a.m.XMLHttpRequest,a.open("GET",b,!0),a.send())}function Fb(a){var b=u.btoa(a.j);a.m[b]&&Z(a,R(a.g,5))};(function(a,b){u[a]=function(){var c=ma.apply(0,arguments);u[a]=function(){};b.call.apply(b,[null].concat(c instanceof Array?c:fa(n(c))))}})("__h82AlnkH6D91__",function(a){typeof window.atob==="function"&&(new Db(window,zb(window.atob(a)))).start()});}).call(this);

window.__h82AlnkH6D91__("WyJwdWItNjQ2Njc1MDgxMDE3Mjc2NyIsW251bGwsbnVsbCxudWxsLCJodHRwczovL2Z1bmRpbmdjaG9pY2VzbWVzc2FnZXMuZ29vZ2xlLmNvbS9iL3B1Yi02NDY2NzUwODEwMTcyNzY3Il0sbnVsbCxudWxsLCJodHRwczovL2Z1bmRpbmdjaG9pY2VzbWVzc2FnZXMuZ29vZ2xlLmNvbS9lbC9BR1NLV3hXQWxGcVkzeHdKMmljMllfdFVkZ09iSGp0MXBjc1VjZDNFOHJCTUctdTktc0NRYjctUTBiRDdLYUVURWF0YUVZdDRmdDJUSDdldHFSMHM4UHRvcHJPbnpBXHUwMDNkXHUwMDNkP3RlXHUwMDNkVE9LRU5fRVhQT1NFRCIsImh0dHBzOi8vZnVuZGluZ2Nob2ljZXNtZXNzYWdlcy5nb29nbGUuY29tL2VsL0FHU0tXeFU3QWM5VG9hSExKSWtzSy1RdGpSM0pOSmg1T2djNzBQbGt1VUlTTmhLbGs2RDJ0SXV2NHF3VWc2eVYxc0JULWFmc3Iya3ZyNG5hME5YWFlOWTN0TUhfS1FcdTAwM2RcdTAwM2Q/YWJcdTAwM2QxXHUwMDI2c2JmXHUwMDNkMSIsImh0dHBzOi8vZnVuZGluZ2Nob2ljZXNtZXNzYWdlcy5nb29nbGUuY29tL2VsL0FHU0tXeFZKUnRqU1RsS1o3d00tdlNfNmdyY0VLRWh2Y1hkMWJxbVpXMGg5a3h2cWhKelFEZENpdjkwcjVyRDhOb1hnSy1oQzRxZ3FBb3BKUzQyekJ1TmYtSkFjQVFcdTAwM2RcdTAwM2Q/YWJcdTAwM2QyXHUwMDI2c2JmXHUwMDNkMSIsImh0dHBzOi8vZnVuZGluZ2Nob2ljZXNtZXNzYWdlcy5nb29nbGUuY29tL2VsL0FHU0tXeFZKN1JucWp3aW5oMEVBRUtWc1VuSGY3dzVOQ3NMLUd0aFp4dXBjcVItTTQzMlI2NjBIOTRxVkVoX19ITVdCZndxNnZiSERJVXFVZTFWZ09mV3JKajE0WEFcdTAwM2RcdTAwM2Q/c2JmXHUwMDNkMiIsImRpdi1ncHQtYWQiLDIwLDEwMCwiY0hWaUxUWTBOalkzTlRBNE1UQXhOekkzTmpjXHUwMDNkIixbbnVsbCxudWxsLG51bGwsImh0dHBzOi8vd3d3LmdzdGF0aWMuY29tLzBlbW4vZi9wL3B1Yi02NDY2NzUwODEwMTcyNzY3LmpzP3VzcXBcdTAwM2RDQVkiXSwiaHR0cHM6Ly9mdW5kaW5nY2hvaWNlc21lc3NhZ2VzLmdvb2dsZS5jb20vZWwvQUdTS1d4VkZuRFZIX0hTenVhYmxTRklrdWx5VU5Ba2dGU2tOdUNFN29PNUs4NlVMMzl4QVN0UU9fU3FBaWFzWDVnSDRIOHhpTVBQTnJJTnVMS2J5QUdrZ3dDclh6Z1x1MDAzZFx1MDAzZCJd");</script>
  <link rel="apple-touch-icon" sizes="76x76" href="/img/fluid.png">
  <link rel="icon" href="/img/fluid.png">
  

  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
    <meta name="baidu-site-verification" content="codeva-OCQ7ylLcn1" />
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="zhengcookie">
  <meta name="keywords" content="zhengcookie,blog,个人博客,技术分享">
  
    <meta name="description" content="[]    .video-container {     position: relative;     width: 100%;     padding-top: 56.25%; &#x2F;* 16:9 aspect ratio (height&#x2F;width &#x3D; 9&#x2F;16 * 100%) *&#x2F; }  .video-container iframe {     position: absolute;">
<meta property="og:type" content="article">
<meta property="og:title" content="AI大模型学习">
<meta property="og:url" content="https://www.zhengcookie.site/zhengcookie/AI%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0/index.html">
<meta property="og:site_name" content="zhengcookie">
<meta property="og:description" content="[]    .video-container {     position: relative;     width: 100%;     padding-top: 56.25%; &#x2F;* 16:9 aspect ratio (height&#x2F;width &#x3D; 9&#x2F;16 * 100%) *&#x2F; }  .video-container iframe {     position: absolute;">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/zhengcookie/tuchuang@main/img/1766046923044-43b4b7f9-649d-4450-97d9-02ac0c46ca7f.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/zhengcookie/tuchuang@main/img/1766048463141-dca6f4c9-66ba-4b3e-9c20-42d904dfa3c7.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/zhengcookie/tuchuang@main/img/1766048597312-7b3fde0d-4483-4d79-9b07-f7a5da1d3347.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/zhengcookie/tuchuang@main/img/1766048764193-ee7a1f24-ce5a-4692-a68b-0197fcea4314.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/zhengcookie/tuchuang@main/img/1766049113577-b909e089-68c0-4a60-9cff-6f119032dfcf.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/zhengcookie/tuchuang@main/img/1766049190107-11cac79e-12f2-4cd5-8269-120a1ad236f2.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/zhengcookie/tuchuang@main/img/1766049287600-270b12ad-c73d-423b-93b9-9a9a708dab2f.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/zhengcookie/tuchuang@main/img/1766049356850-8b1bb26b-e2dc-4a85-a6f4-41bf318e7928.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/zhengcookie/tuchuang@main/img/image-20251224194539575.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/zhengcookie/tuchuang@main/img/1766049425818-05035746-d163-49e0-9929-8f9d76f5a228.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/zhengcookie/tuchuang@main/img/1766049579943-2a76f1a7-80d7-4310-a4f2-c8b61bc94177.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/zhengcookie/tuchuang@main/img/1766049597461-db478700-4ca6-4be5-a3bd-dd573c4a1cd1.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/zhengcookie/tuchuang@main/img/1766049618819-1b094465-59cb-4383-be26-d3914a812c5d.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/zhengcookie/tuchuang@main/img/1766051072389-10c9e01c-51b0-41bd-b8da-2303603eb12a.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/zhengcookie/tuchuang@main/img/1766049670250-5fc5a388-1cc2-4d39-9548-26769128fca8.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/zhengcookie/tuchuang@main/img/1766051756268-eb0d6c13-174d-4876-ab89-5b3c9e2e498b.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/zhengcookie/tuchuang@main/img/1766051846313-8a1dec09-39b2-4728-846c-de0a958fb822.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/zhengcookie/tuchuang@main/img/image-20251224195437775.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/zhengcookie/tuchuang@main/img/1766052825703-c42aaade-94d0-4656-97e6-b2a5c6ba1261.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/zhengcookie/tuchuang@main/img/1766053239598-a3a57817-f3ea-450d-bd56-5ee9f94a7606.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/zhengcookie/tuchuang@main/img/1766053278114-96774c5b-499e-4249-87fd-cd3d8ce12213.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/zhengcookie/tuchuang@main/img/1766053324153-f1563548-104f-45fb-b64d-010d3c9d15fb.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/zhengcookie/tuchuang@main/img/1766053390008-230d0d7f-30b5-4ca1-b0b0-5266148cc257.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/zhengcookie/tuchuang@main/img/1766054063306-184912ac-02cb-436a-8c3b-945fb2dc09f4.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/zhengcookie/tuchuang@main/img/1766054169528-bf94fd5c-cb96-4077-bf19-4224f582ec77.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/zhengcookie/tuchuang@main/img/1766053480429-1bf6184b-a68f-40e4-9c84-13910b9c2b4e.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/zhengcookie/tuchuang@main/img/1766054347400-9463e8cc-2921-4e93-8176-281d26611ecb.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/zhengcookie/tuchuang@main/img/1766054454849-dfbee1f9-cc72-40f0-bfac-f979a9b4655b.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/zhengcookie/tuchuang@main/img/1766054507666-6c5d1b49-36cd-4f40-b6c4-c6818468408f.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/zhengcookie/tuchuang@main/img/image-20251224195618519.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/zhengcookie/tuchuang@main/img/image-20251224195719092.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/zhengcookie/tuchuang@main/img/image-20251224195732171.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/zhengcookie/tuchuang@main/img/1766054674741-e873d4ed-3659-45f5-93f0-4a1d8beeca6b.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/zhengcookie/tuchuang@main/img/image-20251224195744652.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/zhengcookie/tuchuang@main/img/image-20251224195839067.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/zhengcookie/tuchuang@main/img/image-20251224195856760.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/zhengcookie/tuchuang@main/img/1766054957460-4da50ce0-5e47-4c11-a4ab-dea821468a15.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/zhengcookie/tuchuang@main/img/image-20251224200007284.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/zhengcookie/tuchuang@main/img/image-20251224200029670.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/zhengcookie/tuchuang@main/img/1766055493403-4624d8d5-13e5-4195-b003-a917a0657965.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/zhengcookie/tuchuang@main/img/1766055170364-d52495e0-98ea-4dd7-ac99-ef55660728e4.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/zhengcookie/tuchuang@main/img/image-20251224021425633.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/zhengcookie/tuchuang@main/img/1766056428445-950f35bb-a739-4536-a9ff-31cdd7866b69.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/zhengcookie/tuchuang@main/img/1766056479480-94de5713-01c1-4d26-a397-ece20d91c8ff.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/zhengcookie/tuchuang@main/img/1766057555821-4fcadbc3-0fa3-4678-b7af-a8f1c4ace229.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/zhengcookie/tuchuang@main/img/image-20260108235638803.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/zhengcookie/tuchuang@main/img/image-20260109000320243.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/zhengcookie/tuchuang@main/img/image-20260109000615421.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/zhengcookie/tuchuang@main/img/image-20260109000819688.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/zhengcookie/tuchuang@main/img/image-20260109000910123.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/zhengcookie/tuchuang@main/img/image-20260109000957748.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/zhengcookie/tuchuang@main/img/image-20260109001032605.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/zhengcookie/tuchuang@main/img/image-20260109001229637.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/zhengcookie/tuchuang@main/img/image-20260109001525265.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/zhengcookie/tuchuang@main/img/image-20260109001711006.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/zhengcookie/tuchuang@main/img/image-20260109001748033.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/zhengcookie/tuchuang@main/img/image-20260109001813263.png">
<meta property="article:published_time" content="2025-12-23T17:52:26.000Z">
<meta property="article:modified_time" content="2026-01-08T17:26:56.440Z">
<meta property="article:author" content="zhengcookie">
<meta property="article:tag" content="zhengcookie,blog,个人博客,技术分享">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="https://cdn.jsdelivr.net/gh/zhengcookie/tuchuang@main/img/1766046923044-43b4b7f9-649d-4450-97d9-02ac0c46ca7f.png">
  
  
  
  <title>AI大模型学习 - zhengcookie</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/c/font_1749284_5i9bdhy70f8.css">



<link rel="stylesheet" href="//at.alicdn.com/t/c/font_1736178_k526ubmyhba.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  



  
<link rel="stylesheet" href="//cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.css">



  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"www.zhengcookie.site","root":"/","version":"1.9.8","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":true,"follow_dnt":true,"baidu":"b3138381047e1b607c5ad90e1710ecdc","google":null,"tencent":{"sid":null,"cid":null},"leancloud":{"app_id":"sTZBx4mwQ0t3yfqJB5XmuIhz-gzGzoHsz","app_key":"KJPXk2hOqDfll4hbw93yYmUc","server_url":"https://stzbx4mw.lc-cn-n1-shared.com","path":"window.location.pathname","ignore_local":true},"umami":{"src":null,"website_id":null,"domains":null,"start_time":"2024-01-01T00:00:00.000Z","token":null,"api_server":null},"woyaola":null,"cnzz":null},"search_path":"/search.xml","include_content_in_search":true};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
  

  
    <!-- Baidu Analytics -->
    <script async>
      if (!Fluid.ctx.dnt) {
        var _hmt = _hmt || [];
        (function() {
          var hm = document.createElement("script");
          hm.src = "https://hm.baidu.com/hm.js?b3138381047e1b607c5ad90e1710ecdc";
          var s = document.getElementsByTagName("script")[0];
          s.parentNode.insertBefore(hm, s);
        })();
      }
    </script>
  

  

  

  

  
    
  



  
<meta name="generator" content="Hexo 7.3.0"><link rel="alternate" href="/atom.xml" title="zhengcookie" type="application/atom+xml">
</head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>zhengcookie</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/" target="_self">
                <i class="iconfont icon-home-fill"></i>
                <span>首页</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/music/" target="_self">
                <i class="iconfont icon-music"></i>
                <span>音乐</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/" target="_self">
                <i class="iconfont icon-archive-fill"></i>
                <span>归档</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/" target="_self">
                <i class="iconfont icon-category-fill"></i>
                <span>分类</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/" target="_self">
                <i class="iconfont icon-tags-fill"></i>
                <span>标签</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/" target="_self">
                <i class="iconfont icon-user-fill"></i>
                <span>关于</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/links/" target="_self">
                <i class="iconfont icon-link-fill"></i>
                <span>友链</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/works/" target="_self">
                <i class="iconfont icon-works"></i>
                <span>作品</span>
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              <i class="iconfont icon-search"></i>
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">
              <i class="iconfont icon-dark" id="color-toggle-icon"></i>
            </a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/img/default.png') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="AI大模型学习"></span>
          
        </div>

        
          
  <div class="mt-3">
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2025-12-24 01:52" pubdate>
          星期三, 十二月 24日 2025, 1:52 凌晨
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          <!-- compatible with older versions-->
          17k 字
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          <!-- compatible with older versions-->
          138 分钟
        
      </span>
    

    
    
      
        <span id="leancloud-page-views-container" class="post-meta" style="display: none">
          <i class="iconfont icon-eye" aria-hidden="true"></i>
          <span id="leancloud-page-views"></span> 次
        </span>
        
      
      
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <h1 id="seo-header">AI大模型学习</h1>
            
            
              <div class="markdown-body">
                
                <div class="video-container">
[<iframe src="//player.bilibili.com/player.html?isOutside=true&aid=115389581303333&bvid=BV1u9W7zCEmh&cid=33157548834&p=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"></iframe>]
</div>

<style>
.video-container {
    position: relative;
    width: 100%;
    padding-top: 56.25%; /* 16:9 aspect ratio (height/width = 9/16 * 100%) */
}

.video-container iframe {
    position: absolute;
    top: 0;
    left: 0;
    width: 100%;
    height: 100%;
}
</style>

<h1 id="入门篇"><a href="#入门篇" class="headerlink" title="入门篇"></a>入门篇</h1><h2 id="从函数到神经网络"><a href="#从函数到神经网络" class="headerlink" title="从函数到神经网络"></a>从函数到神经网络</h2><h3 id="函数"><a href="#函数" class="headerlink" title="函数"></a>函数</h3><h4 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h4><p>在早期的人工智能研究中，有一种观点认为可以通过找到一个精确的数学函数来表达和解决所有问题。这种想法基于一种信念：即世界上的每一种现象或规律都可以通过某种形式的函数关系来描述。然而，随着研究的深入，人们逐渐认识到现实世界的复杂性远超最初的想象。</p>
<h4 id="符号主义"><a href="#符号主义" class="headerlink" title="符号主义"></a>符号主义</h4><p>符号主义是早期人工智能的一个重要流派，它试图通过逻辑推理、规则匹配等方法来模拟人类的思维过程。这种方法的核心在于寻找并利用那些能够准确描述问题本质的“规律”。然而，在面对极其复杂的现实情况时，符号主义遇到了难以克服的挑战——即如何全面而准确地捕捉到这些规律。</p>
<h4 id="转向近似解"><a href="#转向近似解" class="headerlink" title="转向近似解"></a>转向近似解</h4><p>由于直接找到完美匹配所有情况下的通用法则变得几乎不可能，研究人员开始转向另一种思路：即使不能得到完全正确的答案，但至少可以尝试获得一个足够接近真实结果的近似解。这种方法更加灵活，并且能够在一定程度上缓解了对绝对精度的要求。</p>
<h4 id="联结主义"><a href="#联结主义" class="headerlink" title="联结主义"></a>联结主义</h4><p>当传统的方法无法有效解决问题时，联结主义提供了一种全新的视角。联结主义主张模仿大脑神经元之间的连接方式来构建模型，通过训练让系统自动学习数据中的模式。这实际上是一种“猜测”加“简化”的策略，其中关键在于如何有效地估计权重（w）和偏置（b）参数值。</p>
<ul>
<li><strong>线性模型</strong>：最简单的形式就是线性方程 f(x) = wx + b，其中 w 表示输入 x 对输出的影响程度，b 则是一个常数项。</li>
<li><strong>激活函数</strong>：为了使模型能够处理非线性的关系，引入了激活函数 g()。例如，sigmoid 或 ReLU 等函数可以将线性组合的结果转换为更复杂的非线性映射。</li>
</ul>
<h4 id="通过组合构建复杂关系"><a href="#通过组合构建复杂关系" class="headerlink" title="通过组合构建复杂关系"></a>通过组合构建复杂关系</h4><p>通过不断地将线性和非线性激活函数相结合，可以创建出非常强大的模型来表示极为复杂的关系。尽管这种方式极大地增强了模型的表现力，但也带来了计算上的难度以及理解上的挑战。</p>
<h4 id="神经网络"><a href="#神经网络" class="headerlink" title="神经网络"></a>神经网络</h4><p>神经网络是上述思想的具体实现之一。它由多个层次组成，每个层次包含若干个节点（类似于神经元），这些节点之间通过权重相连。整个网络的工作原理可以用公式 f(x) = g(wx+b) 来概括，其中 g() 是激活函数，wx+b 则是对输入进行线性变换后的结果。通过调整各层之间的权重和偏置，神经网络能够学习到从输入到输出之间复杂的映射关系，从而实现诸如图像识别、自然语言处理等多种任务。<br>总之，从最初的追求精确到后来接受近似，再到采用更加直观且灵活的联结主义方法，人工智能的发展历程体现了科学研究不断适应新挑战的过程。</p>
<p> 输入层  输出层</p>
<p>  x              y</p>
<p>复杂一点像下图这样 ↓</p>
<p><img src="https://cdn.jsdelivr.net/gh/zhengcookie/tuchuang@main/img/1766046923044-43b4b7f9-649d-4450-97d9-02ac0c46ca7f.png" srcset="/img/loading.gif" lazyload alt="img"></p>
<h2 id="计算神经网络的参数"><a href="#计算神经网络的参数" class="headerlink" title="计算神经网络的参数"></a>计算神经网络的参数</h2><h3 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h3><p>如图</p>
<p>y为真实数据 y^为预测数据</p>
<p><img src="https://cdn.jsdelivr.net/gh/zhengcookie/tuchuang@main/img/1766048463141-dca6f4c9-66ba-4b3e-9c20-42d904dfa3c7.png" srcset="/img/loading.gif" lazyload alt="img"></p>
<p>用于真实值与预测值的误差</p>
<p><img src="https://cdn.jsdelivr.net/gh/zhengcookie/tuchuang@main/img/1766048597312-7b3fde0d-4483-4d79-9b07-f7a5da1d3347.png" srcset="/img/loading.gif" lazyload alt="img"></p>
<p>我们可以把所有真实值和预测值加起来，这样可以得到预测数据和真实数据之间的总的误差（拟合度）</p>
<p><img src="https://cdn.jsdelivr.net/gh/zhengcookie/tuchuang@main/img/1766048764193-ee7a1f24-ce5a-4692-a68b-0197fcea4314.png" srcset="/img/loading.gif" lazyload alt="img"></p>
<h4 id="均方误差-MSE"><a href="#均方误差-MSE" class="headerlink" title="均方误差 (MSE)"></a>均方误差 (MSE)</h4><p>因为绝对值不平滑，我们用平方来代替，一来解决绝对值的误差，二来放大误差较大的值的影响，我们再根据样本的数量平均一下，消除样本数量大小的影响，我们把损失函数记成L，就得到下面的公式</p>
<p><img src="https://cdn.jsdelivr.net/gh/zhengcookie/tuchuang@main/img/1766049113577-b909e089-68c0-4a60-9cff-6f119032dfcf.png" srcset="/img/loading.gif" lazyload alt="img"></p>
<p>参数视角则为</p>
<p><img src="https://cdn.jsdelivr.net/gh/zhengcookie/tuchuang@main/img/1766049190107-11cac79e-12f2-4cd5-8269-120a1ad236f2.png" srcset="/img/loading.gif" lazyload alt="img"></p>
<h5 id="简单的线性函数"><a href="#简单的线性函数" class="headerlink" title="简单的线性函数"></a>简单的线性函数</h5><p><img src="https://cdn.jsdelivr.net/gh/zhengcookie/tuchuang@main/img/1766049287600-270b12ad-c73d-423b-93b9-9a9a708dab2f.png" srcset="/img/loading.gif" lazyload alt="img"></p>
<h6 id="演化过程"><a href="#演化过程" class="headerlink" title="演化过程"></a>演化过程</h6><p>展开损失函数</p>
<p><img src="https://cdn.jsdelivr.net/gh/zhengcookie/tuchuang@main/img/1766049356850-8b1bb26b-e2dc-4a85-a6f4-41bf318e7928.png" srcset="/img/loading.gif" lazyload alt="img"></p>
<p>把y^代入</p>
<p><img src="https://cdn.jsdelivr.net/gh/zhengcookie/tuchuang@main/img/image-20251224194539575.png" srcset="/img/loading.gif" lazyload alt="image-20251224194539575"></p>
<p>求和符号展开</p>
<p><img src="https://cdn.jsdelivr.net/gh/zhengcookie/tuchuang@main/img/1766049425818-05035746-d163-49e0-9929-8f9d76f5a228.png" srcset="/img/loading.gif" lazyload alt="img"></p>
<p>把上面这组数据带进来（视频里给的最后一个3-4w，大概率是写错了）</p>
<p><img src="https://cdn.jsdelivr.net/gh/zhengcookie/tuchuang@main/img/1766049579943-2a76f1a7-80d7-4310-a4f2-c8b61bc94177.png" srcset="/img/loading.gif" lazyload alt="img"></p>
<p>平方展开,代入公式是a^2 - 2ab +b^2</p>
<p><img src="https://cdn.jsdelivr.net/gh/zhengcookie/tuchuang@main/img/1766049597461-db478700-4ca6-4be5-a3bd-dd573c4a1cd1.png" srcset="/img/loading.gif" lazyload alt="img"></p>
<p>化简结果</p>
<p><img src="https://cdn.jsdelivr.net/gh/zhengcookie/tuchuang@main/img/1766049618819-1b094465-59cb-4383-be26-d3914a812c5d.png" srcset="/img/loading.gif" lazyload alt="img"></p>
<p>求导，怎么求呢</p>
<p>图一</p>
<p><img src="https://cdn.jsdelivr.net/gh/zhengcookie/tuchuang@main/img/1766051072389-10c9e01c-51b0-41bd-b8da-2303603eb12a.png" srcset="/img/loading.gif" lazyload alt="img"></p>
<p> <strong>计算 w^x = x个 w</strong><br><strong>原题中</strong></p>
<p><strong>常数项为0，因为他不随w变化</strong></p>
<p><strong>一次项w 一个w在变 -&gt;变化算一次 所以乘以1</strong></p>
<p><strong>两次项 俩个w在变 → 变化算两次 → 乘 2</strong></p>
<p>所以：d/dw(7.5w^2) = 7.5 · 2w = 15</p>
<p>结果</p>
<p><img src="https://cdn.jsdelivr.net/gh/zhengcookie/tuchuang@main/img/1766049670250-5fc5a388-1cc2-4d39-9548-26769128fca8.png" srcset="/img/loading.gif" lazyload alt="img"></p>
<p>要求最小值，带入进来就是</p>
<p><img src="https://cdn.jsdelivr.net/gh/zhengcookie/tuchuang@main/img/1766051756268-eb0d6c13-174d-4876-ab89-5b3c9e2e498b.png" srcset="/img/loading.gif" lazyload alt="img"></p>
<p>导数等于0，就可以得到</p>
<p>带入为原直线函数，</p>
<p><img src="https://cdn.jsdelivr.net/gh/zhengcookie/tuchuang@main/img/1766051846313-8a1dec09-39b2-4728-846c-de0a958fb822.png" srcset="/img/loading.gif" lazyload alt="img"></p>
<p> y 是模型的输出（预测值 ）这个 y 预测损失多少</p>
<p>此时y=x就是让损失函数最小，也就是最拟合真实数据的那条直线</p>
<p><img src="https://cdn.jsdelivr.net/gh/zhengcookie/tuchuang@main/img/image-20251224195437775.png" srcset="/img/loading.gif" lazyload alt="image-20251224195437775"></p>
<p>所以它（损失函数）实际上就是一条开口向上的抛物线，我们刚刚就在寻找最低点，采用的办法就是导数=0</p>
<p><img src="https://cdn.jsdelivr.net/gh/zhengcookie/tuchuang@main/img/1766052825703-c42aaade-94d0-4656-97e6-b2a5c6ba1261.png" srcset="/img/loading.gif" lazyload alt="img"></p>
<h5 id="复杂的线性函数"><a href="#复杂的线性函数" class="headerlink" title="复杂的线性函数"></a>复杂的线性函数</h5><p><img src="https://cdn.jsdelivr.net/gh/zhengcookie/tuchuang@main/img/1766053239598-a3a57817-f3ea-450d-bd56-5ee9f94a7606.png" srcset="/img/loading.gif" lazyload alt="img"></p>
<p>图像来解释就是一个三维图像，一个开口向上的网状形状</p>
<p><img src="https://cdn.jsdelivr.net/gh/zhengcookie/tuchuang@main/img/1766053278114-96774c5b-499e-4249-87fd-cd3d8ce12213.png" srcset="/img/loading.gif" lazyload alt="img"></p>
<p>我们要找到的就是这个二元函数最小值对应的w和b</p>
<p><img src="https://cdn.jsdelivr.net/gh/zhengcookie/tuchuang@main/img/1766053324153-f1563548-104f-45fb-b64d-010d3c9d15fb.png" srcset="/img/loading.gif" lazyload alt="img"></p>
<p>那么就不再是计算导数，而是偏导数来求解</p>
<p><img src="https://cdn.jsdelivr.net/gh/zhengcookie/tuchuang@main/img/1766053390008-230d0d7f-30b5-4ca1-b0b0-5266148cc257.png" srcset="/img/loading.gif" lazyload alt="img"></p>
<p>对w求偏导，就是把b当作常数，在三维图像就是这样的，相当于只看到这个切面</p>
<p><img src="https://cdn.jsdelivr.net/gh/zhengcookie/tuchuang@main/img/1766054063306-184912ac-02cb-436a-8c3b-945fb2dc09f4.png" srcset="/img/loading.gif" lazyload alt="img"></p>
<p>对于b也是如此，对b求偏导，就是把w当作常数，在三维图像就是这样的，相当于只看到这个切面</p>
<p><img src="https://cdn.jsdelivr.net/gh/zhengcookie/tuchuang@main/img/1766054169528-bf94fd5c-cb96-4077-bf19-4224f582ec77.png" srcset="/img/loading.gif" lazyload alt="img"></p>
<h6 id="线性回归"><a href="#线性回归" class="headerlink" title="线性回归"></a>线性回归</h6><p>通过寻找一个线性函数，来拟合x和y之间的关系，也就是机器学习中最基本的一种分析方法，我们叫他线性回归</p>
<p><img src="https://cdn.jsdelivr.net/gh/zhengcookie/tuchuang@main/img/1766053480429-1bf6184b-a68f-40e4-9c84-13910b9c2b4e.png" srcset="/img/loading.gif" lazyload alt="img"></p>
<p>往往呢，我们不能通过像刚刚那样将导数=0来计算出最小值</p>
<p>解决办法呢，简单除暴一点就是一点点试</p>
<p>假如w为5，b为5，损失函数计算结果为10</p>
<p><img src="https://cdn.jsdelivr.net/gh/zhengcookie/tuchuang@main/img/1766054347400-9463e8cc-2921-4e93-8176-281d26611ecb.png" srcset="/img/loading.gif" lazyload alt="img"></p>
<p>我们调整了w为6，损失函数为9，这说明w增加让损失函数的值变小了。</p>
<p><img src="https://cdn.jsdelivr.net/gh/zhengcookie/tuchuang@main/img/1766054454849-dfbee1f9-cc72-40f0-bfac-f979a9b4655b.png" srcset="/img/loading.gif" lazyload alt="img"></p>
<p>再尝试b增加1，结果为11.损失函数增加2，说明b增加让损失函数的值变大了，误差变大了。</p>
<p><img src="https://cdn.jsdelivr.net/gh/zhengcookie/tuchuang@main/img/1766054507666-6c5d1b49-36cd-4f40-b6c4-c6818468408f.png" srcset="/img/loading.gif" lazyload alt="img"></p>
<p>我们就反过来对b进行减少，让损失函数继续变小</p>
<p><img src="https://cdn.jsdelivr.net/gh/zhengcookie/tuchuang@main/img/image-20251224195618519.png" srcset="/img/loading.gif" lazyload alt="image-20251224195618519"></p>
<p><img src="https://cdn.jsdelivr.net/gh/zhengcookie/tuchuang@main/img/image-20251224195719092.png" srcset="/img/loading.gif" lazyload alt="image-20251224195719092"></p>
<p>w变化一点点，使得损失函数也发生变化。</p>
<p><img src="https://cdn.jsdelivr.net/gh/zhengcookie/tuchuang@main/img/image-20251224195732171.png" srcset="/img/loading.gif" lazyload alt="image-20251224195732171"></p>
<p>这其实是损失函数对w的偏导数</p>
<p><img src="https://cdn.jsdelivr.net/gh/zhengcookie/tuchuang@main/img/1766054674741-e873d4ed-3659-45f5-93f0-4a1d8beeca6b.png" srcset="/img/loading.gif" lazyload alt="img"></p>
<p>对b也是如此</p>
<p><img src="https://cdn.jsdelivr.net/gh/zhengcookie/tuchuang@main/img/image-20251224195744652.png" srcset="/img/loading.gif" lazyload alt="image-20251224195744652"></p>
<p>我们要做的其实就是w和b不断网偏导数的反方向去变化</p>
<p><img src="https://cdn.jsdelivr.net/gh/zhengcookie/tuchuang@main/img/image-20251224195839067.png" srcset="/img/loading.gif" lazyload alt="image-20251224195839067"></p>
<p>具体的变化快慢呢，我们用一个系数n来表示，我们叫他学习率</p>
<p><img src="https://cdn.jsdelivr.net/gh/zhengcookie/tuchuang@main/img/image-20251224195856760.png" srcset="/img/loading.gif" lazyload alt="image-20251224195856760"></p>
<h6 id="梯度"><a href="#梯度" class="headerlink" title="梯度"></a>梯度</h6><p>这些导数所构成的向量，我们就叫他梯度</p>
<p><img src="https://cdn.jsdelivr.net/gh/zhengcookie/tuchuang@main/img/1766054957460-4da50ce0-5e47-4c11-a4ab-dea821468a15.png" srcset="/img/loading.gif" lazyload alt="img"></p>
<h6 id="梯度下降"><a href="#梯度下降" class="headerlink" title="梯度下降"></a>梯度下降</h6><p>不断变化w和b，让损失函数逐渐变小的一个过程，进而求出最终的w和b，这个过程我们叫他梯度下降。</p>
<p><img src="https://cdn.jsdelivr.net/gh/zhengcookie/tuchuang@main/img/image-20251224200007284.png" srcset="/img/loading.gif" lazyload alt="image-20251224200007284"></p>
<p>偏导数如何求？</p>
<p>神经网络中，虽然函数本身是一个复杂到变态的非线性函数，直接求导不好求。</p>
<p>但是，层与层之间的关系，确实非常简单的，我们就用前面的这个神经网络结构来举例</p>
<p><img src="https://cdn.jsdelivr.net/gh/zhengcookie/tuchuang@main/img/image-20251224200029670.png" srcset="/img/loading.gif" lazyload alt="image-20251224200029670"></p>
<p>只有一个输入和输出，而且中间只有一个隐藏层。</p>
<p>我们通过x来计算出隐藏层a的值，这个g就是随便一个激活函数，比如sigmod<img src="https://cdn.jsdelivr.net/gh/zhengcookie/tuchuang@main/img/1766055493403-4624d8d5-13e5-4195-b003-a917a0657965.png" srcset="/img/loading.gif" lazyload alt="img"></p>
<p>再根据a的值计算出y^的值，然后根据y^的值以及真实值y计算出损失函数L，损失函数就用均方误差了。</p>
<p><img src="https://cdn.jsdelivr.net/gh/zhengcookie/tuchuang@main/img/1766055170364-d52495e0-98ea-4dd7-ac99-ef55660728e4.png" srcset="/img/loading.gif" lazyload alt="img"></p>
<p>由于只有一个输出数据，所以把求符号省略掉了</p>
<p><img src="https://cdn.jsdelivr.net/gh/zhengcookie/tuchuang@main/img/image-20251224021425633.png" srcset="/img/loading.gif" lazyload alt="image-20251224021425633"></p>
<h6 id="链式法则"><a href="#链式法则" class="headerlink" title="链式法则"></a>链式法则</h6><p>这个神经网络中共有4个参数，w1和w2，b1和b2要通过梯度下降的方式逐渐求解。</p>
<p>w1变化多少，会让L变化多少。</p>
<p>我们就看w1变化一个单位，a变化多少</p>
<p>再看a变化一个单位，会让y^变化多少</p>
<p>最后看y^变化一个单位，会对L变化多少</p>
<p><img src="https://cdn.jsdelivr.net/gh/zhengcookie/tuchuang@main/img/1766056428445-950f35bb-a739-4536-a9ff-31cdd7866b69.png" srcset="/img/loading.gif" lazyload alt="img"></p>
<p>把三者相乘，就知道w变化一个单位，会使得L变化多少了</p>
<p><img src="https://cdn.jsdelivr.net/gh/zhengcookie/tuchuang@main/img/1766056479480-94de5713-01c1-4d26-a397-ece20d91c8ff.png" srcset="/img/loading.gif" lazyload alt="img"></p>
<p>也就是微积分中的复合函数求导，在这里也叫做链式法则。</p>
<h6 id="反向传播"><a href="#反向传播" class="headerlink" title="反向传播"></a>反向传播</h6><p>因为我们可以从右向左计算求导公式，逐步更新每一层的参数，直到把所有的神经网络的参数，都计算一遍，所以前面计算用到的偏导数的值后面也会用到，所以不必计算太多，而是让这些值从右向左一点点传播过来，这个过程就叫做反向传播。</p>
<p><strong>训练</strong></p>
<p>我们通过前向传播输入x计算输出y，通过反向传播计算出损失函数个参数的梯度，每个参数都向着梯度的反方向变化，这就构成了神经网络的训练。当神经网络进行足够多的训练，直到让损失函数足够小，也就是找到了我们需要的那个函数。</p>
<p><img src="https://cdn.jsdelivr.net/gh/zhengcookie/tuchuang@main/img/1766057555821-4fcadbc3-0fa3-4678-b7af-a8f1c4ace229.png" srcset="/img/loading.gif" lazyload alt="img"></p>
<h2 id="调教神经网络的方法"><a href="#调教神经网络的方法" class="headerlink" title="调教神经网络的方法"></a>调教神经网络的方法</h2><p>我们知道神经网络的本质就是线性变换，套上一个激活函数，不断组合而成的一个非常复杂的非线性函数，并且巧妙地通过梯度下降，</p>
<p>我们可以从肉眼看出下面哪个好，一点点计算出神经网络中的一组合适的参数，那这样看起来只要神经网络足够大，岂不是什么问题都能解决了，理论上确实是这样，但是理想很丰满，现实很骨感，令人头疼的问题很快就接踵而至。</p>
<p>上个视频中我们说过，我们的目标是让数据拟合的好，比如左边这个就拟合的挺好，右边这个就不太好</p>
<p><img src="https://cdn.jsdelivr.net/gh/zhengcookie/tuchuang@main/img/image-20260108235638803.png" srcset="/img/loading.gif" lazyload alt="image-20260108235638803"></p>
<h3 id="过拟合"><a href="#过拟合" class="headerlink" title="过拟合"></a><strong>过拟合</strong></h3><p>那再来一组图，这回你认为是左边好还是右边好呢？</p>
<p><img src="https://cdn.jsdelivr.net/gh/zhengcookie/tuchuang@main/img/image-20260109000320243.png" srcset="/img/loading.gif" lazyload alt="image-20260109000320243"></p>
<p>纯从预测值与真实值误差来看，也就是损失值最小化这个目标来看的话，显然右边这个更好但直觉似乎告诉我们，右边这个好像有点好的太过了，结果可能是只适合训练数据，对新数据的预测反而不如左边的准，那这种在训练数据上表现的很完美，但是在没见过的数据上表现的很糟糕的现象，就叫做过拟合。而在没见过的数据上的表现能力我们叫<code>泛化能力</code>。</p>
<p><img src="https://cdn.jsdelivr.net/gh/zhengcookie/tuchuang@main/img/image-20260109000615421.png" srcset="/img/loading.gif" lazyload alt="image-20260109000615421"></p>
<p>那为什么会过拟合呢。看看刚刚这个图。</p>
<p><img src="https://cdn.jsdelivr.net/gh/zhengcookie/tuchuang@main/img/image-20260109000819688.png" srcset="/img/loading.gif" lazyload alt="image-20260109000819688"></p>
<p>其实就是训练数据本身是个很简单的规律，但模型太复杂了，把那些噪声和随机波动也给学会了，那这该怎么办呢？</p>
<p>自然就是简化一下模型的复杂度</p>
<p>比如说这个案例中</p>
<p>你用一个非常复杂的神经网络模型来训练</p>
<p>效果甚至不如一个线性模型好</p>
<p><img src="https://cdn.jsdelivr.net/gh/zhengcookie/tuchuang@main/img/image-20260109000910123.png" srcset="/img/loading.gif" lazyload alt="image-20260109000910123"></p>
<p>这就告诉我们</p>
<p>神经网络不是越大越好</p>
<p>那简化模型复杂度有效果</p>
<p>与之相对的就是增加训练数据的量</p>
<p><img src="https://cdn.jsdelivr.net/gh/zhengcookie/tuchuang@main/img/image-20260109000957748.png" srcset="/img/loading.gif" lazyload alt="image-20260109000957748"></p>
<p>数据量足够充足</p>
<p>那原本复杂的模型也就相对变得简单了</p>
<p><img src="https://cdn.jsdelivr.net/gh/zhengcookie/tuchuang@main/img/image-20260109001032605.png" srcset="/img/loading.gif" lazyload alt="image-20260109001032605"></p>
<h3 id="数据增强"><a href="#数据增强" class="headerlink" title="数据增强"></a><strong>数据增强</strong></h3><p>但有的时候我们确实无法收集</p>
<p>或者懒得收集更多的数据</p>
<p>怎么办呢</p>
<p>那就在原有的数据中创造更多的数据</p>
<p>比如说在图像处理中</p>
<p>我们可以对图像进行旋转翻转</p>
<p>裁剪加噪声等操作</p>
<p>创造出更多新的训练样本</p>
<p>这就叫做数据增强。</p>
<p><img src="https://cdn.jsdelivr.net/gh/zhengcookie/tuchuang@main/img/image-20260109001229637.png" srcset="/img/loading.gif" lazyload alt="image-20260109001229637"></p>
<h3 id="鲁棒性（Robostness）"><a href="#鲁棒性（Robostness）" class="headerlink" title="鲁棒性（Robostness）"></a>鲁棒性（Robostness）</h3><p>这样不仅仅能够产生更多的数据</p>
<p>还刚好训练了一个让模型不因</p>
<p>输入的一点点小的变化</p>
<p>而对结果产生很大的波动</p>
<p>这就是增强了模型的鲁棒性。</p>
<p>提前终止训练过程</p>
<p>好刚刚是从数据和模型本身入手来防止过拟合</p>
<p>那有没有可能从训练过程入手</p>
<p>阻止过拟合的发生呢</p>
<p>其实训练过程就是不断调整参数的过程吧</p>
<p>那其实只要不让参数继续过分的</p>
<p>向着过拟合的方向发展就可以了</p>
<p><img src="https://cdn.jsdelivr.net/gh/zhengcookie/tuchuang@main/img/image-20260109001525265.png" srcset="/img/loading.gif" lazyload alt="image-20260109001525265"></p>
<p>所以有个简单到你都不敢相信的办法</p>
<p>就是提前终止训练过程</p>
<p>意思就是差不多就行了</p>
<p>不用追求那么完美</p>
<p>不过这种办法还是太粗糙了</p>
<p>像咱们这种精致的人</p>
<p>肯定还得追求一些更精细的办法</p>
<p>也就是说有没有什么办法</p>
<p>能够直接抑制参数的野蛮增长呢</p>
<p>非常简单</p>
<p>你想想看参数是怎么被训练出来的</p>
<p>是不是通过让参数往让损失函数变小的方向</p>
<p>不断调整</p>
<p>也就是梯度下降</p>
<p><img src="https://cdn.jsdelivr.net/gh/zhengcookie/tuchuang@main/img/image-20260109001711006.png" srcset="/img/loading.gif" lazyload alt="image-20260109001711006"></p>
<p>那我们可以在损失函数中</p>
<p>把参数本身的值加上去</p>
<p>这样在参数往大了调整时</p>
<p><img src="https://cdn.jsdelivr.net/gh/zhengcookie/tuchuang@main/img/image-20260109001748033.png" srcset="/img/loading.gif" lazyload alt="image-20260109001748033"></p>
<p>如果让损失函数减小的没有那么多</p>
<p>导致新的损失函数反而是变大的</p>
<p>那么此时调整就是不合适的</p>
<p><img src="https://cdn.jsdelivr.net/gh/zhengcookie/tuchuang@main/img/image-20260109001813263.png" srcset="/img/loading.gif" lazyload alt="image-20260109001813263"></p>
<p>因此一定程度上就抑制了参数的野蛮增长</p>
<p>除了可以用参数的绝对值之和之外</p>
<p>我们还可以用参数的平方和</p>
<p>这样参数大的时候</p>
<p>抑制的效果就更强了</p>
<p>我们把这一项叫做惩罚项</p>
<p>把通过这种向损失函数中添加权重</p>
<p>惩罚项</p>
<p>抑制其野蛮增长的方法叫做正则化</p>
<p>上面这个参数绝对值相加的叫L1正则化呃</p>
<p>下面这个平方向相加的叫L2正则化</p>
<p>然后和之前梯度下降时增加学习率</p>
<p>控制下降力度一样</p>
<p>我们也增加一个参数来控制惩罚项的力度</p>
<p>我们叫它正则化系数</p>
<p>而这些控制参数的参数我们以后统称为超参数</p>
<p>那为什么简简单单的公式叫什么L1正则化</p>
<p>L2正则化呢</p>
<p>因为绝对值之和叫做L1范数</p>
<p>而平方和的平方根叫做L2范数</p>
<p>这是向量空间中范数的概念</p>
<p>唉光是把这些名词术语念上一遍</p>
<p>都比讲这个原理本身还要长</p>
<p>真是苦了各位学习者了</p>
<p>总之这个破玩意儿</p>
<p>就只是为了抑制参数的野蛮增长罢了</p>
<p>呃除了这种方式外</p>
<p>还有一种令人简单到发指</p>
<p>但是就是效果显著的办法</p>
<p>你猜是什么</p>
<p>想想看哈</p>
<p>我们的目的是为了防止让模型过于依赖</p>
<p>某几个参数</p>
<p>举个形象的例子</p>
<p>假如神经网络中的参数是一支军队</p>
<p>里面有好多普通士兵</p>
<p>但是其中混入了一支战斗力极强的闪客</p>
<p>然后你研究各种战术</p>
<p>让士兵和别人打仗</p>
<p>如果每次训练都有闪客主导战局</p>
<p>那么你会误认为整体的战斗力很强</p>
<p>一旦遇到特殊情况</p>
<p>那就会败北</p>
<p>这就是过度依赖少量参数的典型表现</p>
<p>那怎么办呢</p>
<p>我们可以在训练过程中</p>
<p>每次都随机丢弃一部分参数</p>
<p>让闪客偶尔缺席</p>
<p>这样模型就必须学会依赖更多的普通士兵</p>
<p>从而避免了在某些关键参数上过度依赖的风险</p>
<p>虽然听起来有点玄学</p>
<p>但确实十分有效</p>
<p>这种方法叫drop out</p>
<p>其翻译过来就是丢弃</p>
<p>可能你此时会皱紧眉头</p>
<p>这都什么玩意儿</p>
<p>感觉怎么这么儿戏呢</p>
<p>对很无厘头</p>
<p>但没办法就是有效</p>
<p>而且这个方法是大名鼎鼎的深度学习之父</p>
<p>辛顿提出来的</p>
<p>好了上面我们了解了</p>
<p>在对抗过拟合这条路上</p>
<p>我们绞尽脑汁想了各种办法</p>
<p>包括增加数据量</p>
<p>减少模型复杂度</p>
<p>提前终止训练</p>
<p>L1正则化</p>
<p>L2正则化</p>
<p>drop out等等</p>
<p>那除此之外</p>
<p>模型还会遇到其他问题</p>
<p>比如说梯度消失</p>
<p>也就是网络越深</p>
<p>梯度反向传播时会越来越小</p>
<p>导致参数更新困难</p>
<p>梯度爆炸</p>
<p>梯度数值越来越大</p>
<p>参数的调整幅度失去了控制</p>
<p>收敛速度过慢</p>
<p>比如可能陷入局部最优或者来回震荡</p>
<p>计算开销过大</p>
<p>数据供应量太庞大了</p>
<p>每次完整的前向传播和反向传播都非常耗时</p>
<p>那每个问题人们都想了各种办法来解决</p>
<p>比如用梯度裁剪来防止梯度的更新过大</p>
<p>用合理的网络结构</p>
<p>比如残差网络来防止深层网络的梯度衰减</p>
<p>用合理的权重初始化和将输入数据归一化</p>
<p>让梯度分布更平滑</p>
<p>用动量法</p>
<p>r ms is prot adam等自适应优化器来加速收敛</p>
<p>减少震荡</p>
<p>用mini batch把巨量的训练数据分割成几个小批次</p>
<p>来降低单次的计算开销</p>
<p>呃这里的每个概念展开都是一个全新的世界</p>
<p>但他们和我们今天着重讲的内容一样</p>
<p>都是为了让训练过程更好罢了</p>
<p>鉴于我们这个系列是抓大放小</p>
<p>解决主要思想的特点</p>
<p>这里就不一一展开了</p>
<p>对哪个概念</p>
<p>如果特别感兴趣的朋友</p>
<p>可以弹幕或者评论区告诉我</p>
<p>我可以单独出几期拓展视频来讲解</p>
<p>只要神经网络足够大</p>
<p>就能包打天下的局面</p>
<p>正是由于出现了各种各样的困境</p>
<p>人们才想出各种五花八门的应对策略</p>
<p>也让人们不禁感叹</p>
<p>深度学习的确像是一门玄学</p>
<p>当然随着研究的不断深入</p>
<p>还有更多令人惊艳的技巧层出不穷</p>
<p>比如卷积网络</p>
<p>CNN如何利用卷积层池化层处理图片</p>
<p>数据循环网络</p>
<p>RNN如何利用上下文处理序列数据</p>
<p>以及后来的注意力机制</p>
<p>attention的引入催生了transformer</p>
<p>并衍生出了现在的众多大语言模型</p>
<p>让人工智能不仅仅是识别和判断</p>
<p>还可以创造和决策</p>
<h2 id="从矩阵到-CNN"><a href="#从矩阵到-CNN" class="headerlink" title="从矩阵到 CNN"></a>从矩阵到 CNN</h2><p>00:00 最简单的神经网络就是Y等于WX加B</p>
<p>00:03 套上一个激活函数</p>
<p>00:04 那如果输入变成了两个</p>
<p>00:06 那么就是两个W和两个X</p>
<p>00:09 如果输入变成了三个</p>
<p>00:10 那么就是三个W和三个X</p>
<p>00:13 以此类推</p>
<p>00:14 我就不写了</p>
<p>00:16 那如果输出变成两个</p>
<p>00:18 再来一行公式就可以了</p>
<p>00:20 那这里的W的标号保证不一样</p>
<p>00:23 能区分开就行</p>
<p>00:24 比如说这个W12</p>
<p>00:26 就表示第一个神经元的第二个参数</p>
<p>00:31 好你发现一个问题没有</p>
<p>00:34 就是这样写下去的话</p>
<p>00:36 太麻烦了</p>
<p>00:36 要是神经元多了的话</p>
<p>00:38 公是密密麻麻的</p>
<p>00:39 没有数学的简洁之美</p>
<p>00:41 那这怎么办呢</p>
<p>00:42 别急</p>
<p>00:43 现在我们的注意力放在这个公式上</p>
<p>00:46 注意看啊</p>
<p>00:47 我要变形了</p>
<p>00:55 再来一遍</p>
<p>00:57 其实就是把加减乘除替换成了矩阵运算的写法</p>
<p>01:04 额这里先忽略一下激活函数哈</p>
<p>01:07 重点看中间这个矩阵的乘法</p>
<p>01:09 矩阵乘法很简单</p>
<p>01:11 我们错个位</p>
<p>01:12 就是这一行W的元素</p>
<p>01:14 分别和X这一列的元素相乘</p>
<p>01:17 并求和</p>
<p>01:20 得到的结果呢放到这里</p>
<p>01:23 那同样对于第二行也是如此</p>
<p>01:27 回到刚刚</p>
<p>01:28 我们现在把这些矩阵都替换成新的字母</p>
<p>01:31 这里我们用大写的Y表示</p>
<p>01:33 这里用大写的W表示</p>
<p>01:35 这里用大写的X表示</p>
<p>01:37 这里用小写的B来表示</p>
<p>01:39 那么整个公式就化简成了这个样子</p>
<p>01:44 不过现在还有个问题</p>
<p>01:45 就是神经元的层并没有体现在公式中</p>
<p>01:48 那假如神经元再多几层怎么办呢</p>
<p>01:51 那我们此时抽象一下</p>
<p>01:53 也别分什么XY和隐藏层了</p>
<p>01:56 就通通用字母A来表示</p>
<p>01:58 那输入层就当做第零层</p>
<p>02:00 用A中括号零来表示</p>
<p>02:02 以此类推</p>
<p>02:04 那么第一层的公式就是这样</p>
<p>02:06 第二层的公式就是这样</p>
<p>02:09 第三层的公式就是这样</p>
<p>02:11 我们用L表示在第几层</p>
<p>02:14 那么最终的通用公式就是这个样子</p>
<p>02:17 每一层的神经元的值都是上一层的函数</p>
<p>02:22 那我们费了这么大劲</p>
<p>02:23 简化这个公式有啥用呢</p>
<p>02:25 一方面是公式简单了</p>
<p>02:27 也更抽象了</p>
<p>02:28 有利于我们进一步讨论更深的问题</p>
<p>02:31 另一方面是麻烦的加减乘除替换成了矩阵运算</p>
<p>02:35 可以充分利用GPU的并行计算的特性</p>
<p>02:38 加速神经网络的训练和推理过程</p>
<p>02:40 这就不仅仅是秀写法上的一个操作了</p>
<p>02:44 那回到这个公式和神经网络结构</p>
<p>02:47 可以看到这里的每个神经元</p>
<p>02:49 都与前一层的所有神经元相连</p>
<p>02:51 当然我们一直认为这是理所应当的</p>
<p>02:54 但它其实只是神经网络结构中的一种</p>
<p>02:57 叫做全连接层嗯</p>
<p>02:59 也就是说还有其他不是全连接的结构吗</p>
<p>03:02 别急</p>
<p>03:03 我们先来看一下全连接层的问题</p>
<p>03:06 假如我们现在要做个图像识别的模型</p>
<p>03:09 假如输入是个30×30的灰度图像</p>
<p>03:12 那么平铺展开后</p>
<p>03:13 喂给输入层的就是900个神经元呃</p>
<p>03:16 假如下一层的神经元的数量是1000个</p>
<p>03:19 那么这个全连接层的总参数量就达到了90万</p>
<p>03:22 这太大了</p>
<p>03:24 另外呢这里仅仅是把输入的图片平铺展开</p>
<p>03:28 无法保留像素之间的空间关系</p>
<p>03:30 图片稍稍动一下</p>
<p>03:32 可能所有神经元都和原来完全不同</p>
<p>03:34 但从图片整体上看</p>
<p>03:36 可能仅仅是平移或者变暗</p>
<p>03:38 这就是不能很好地理解图像的局部模式</p>
<p>03:41 那怎么办呢</p>
<p>03:43 我们随便在这个图像中取一个3×3的矩阵</p>
<p>03:46 这里面的数值就是颜色的灰度值</p>
<p>03:49 然后我们再来一个固定的矩阵</p>
<p>03:52 比如这样把这两个矩阵进行这样的一个运算</p>
<p>03:56 46×0加上75×-1</p>
<p>03:59 加上82×0</p>
<p>04:01 也就是把每个对应位置处的值相乘并求和</p>
<p>04:05 最终得到一个值是250</p>
<p>04:07 然后我们再选取一个地方再次进行这样的运算</p>
<p>04:12 最终我们把这种运算方式遍历</p>
<p>04:15 划过原图像的每个地方</p>
<p>04:17 得出的数值形成一个新的图像</p>
<p>04:20 那这种方式叫做卷积运算</p>
<p>04:22 而刚刚我们这个固定的矩阵叫做卷积核</p>
<p>04:27 卷积核不是一个新的概念</p>
<p>04:29 在传统的图像处理领域</p>
<p>04:31 卷积核是已知的</p>
<p>04:32 可以达到一定的图像处理效果</p>
<p>04:34 比如模糊效果</p>
<p>04:36 浮雕效果</p>
<p>04:38 轮廓效果以及刚刚的锐化效果等等</p>
<p>04:41 就是PS的常规操作嘛</p>
<p>04:44 那在深度学习领域</p>
<p>04:45 卷积核的值就是未知的</p>
<p>04:47 和神经网络中的其他参数一样</p>
<p>04:50 是被训练出来的一组值</p>
<p>04:52 那回到刚刚的经典神经网络结构</p>
<p>04:55 其实就是把其中一个全连接层替换成了卷积层</p>
<p>04:59 这就大大的减少了权重参数的数量</p>
<p>05:02 同时还能更有效地捕捉到图片中的</p>
<p>05:04 一些局部特征</p>
<p>05:05 可谓是一举两得</p>
<p>05:07 而从公式上看</p>
<p>05:09 其实就是把原来的矩阵的标准乘法及差乘</p>
<p>05:12 替换成了卷积运算</p>
<p>05:16 好</p>
<p>05:16 那接下来我们的神经网络</p>
<p>05:18 就不用再画成一个一个的小圈了</p>
<p>05:21 而用更抽象更简洁的图来表示</p>
<p>05:23 像这样在图像识别的神经网络结构中</p>
<p>05:28 除了卷积层外</p>
<p>05:29 通常还有池化层作用</p>
<p>05:31 是对卷积层后的特征图像进行降维</p>
<p>05:34 减少计算量</p>
<p>05:35 同时呢保留主要特征</p>
<p>05:37 这里的卷积层</p>
<p>05:38 池化层</p>
<p>05:39 全连接层都可以有多个</p>
<p>05:41 而这种适用于图像识别领域的神经网络结构</p>
<p>05:44 就叫做卷积神经网络</p>
<p>05:46 CNN</p>
<p>05:47 之前我们展示的手写数字识别的CNN可视化</p>
<p>05:51 就是这样的网络结构</p>
<p>05:53 最开始是一个输入层</p>
<p>05:55 我们写了一个数字六</p>
<p>05:57 然后是卷积层</p>
<p>05:59 池化层</p>
<p>06:01 再卷积层</p>
<p>06:02 再池化层</p>
<p>06:04 然后第一个全连接层</p>
<p>06:06 第二个全连接层</p>
<p>06:08 最终输出识别出是六</p>
<p>06:13 而使用卷积神经网络非常方便可视化</p>
<p>06:16 我们可以看到训练过程中所训练出的卷积核</p>
<p>06:19 从原始图像中提取了什么样的特征</p>
<p>06:22 虽然这些都是中间隐藏层的事情</p>
<p>06:25 但是却能神奇地观察出一些实际意义</p>
<p>06:28 这也是卷积神经网络让人着迷的地方</p>
<p>06:32 好我们来回顾一下今天讲的内容非常简单</p>
<p>06:36 我们把之前一个一个加减乘除很麻烦的写法</p>
<p>06:39 写成了矩阵的形式</p>
<p>06:41 一是为了方便讨论</p>
<p>06:42 比如刚刚介绍CNN的时候</p>
<p>06:44 就从公式直接看出</p>
<p>06:45 就是差乘变成了卷积运算而已</p>
<p>06:47 二是可以更好的利用GPU的并行计算提高效率</p>
<p>06:51 那接下来我们把之前默认的那种</p>
<p>06:53 所有神经元都连起来的形式叫做全连接</p>
<p>06:56 进而呢通过图像识别这个任务</p>
<p>06:59 意识到了全世界的局限性</p>
<p>07:01 接下来我们通过卷积运算</p>
<p>07:03 代替了全连接层的标准矩阵乘法</p>
<p>07:05 一方面使得训练参数大大的减少</p>
<p>07:08 另外一方面也更有利于提取图像的局部特征</p>
<p>07:11 这就解决了我们一开始说的问题</p>
<p>07:13 最后我们把神经网络结构再次抽象一个层次</p>
<p>07:17 原来我们画的各种小圈圈在更高的视角下</p>
<p>07:20 其实就是个全连接层而已</p>
<p>07:22 那么这些全连接层</p>
<p>07:23 卷积层</p>
<p>07:24 池化层的组合就构成了卷积神经网络CNN</p>
<p>07:28 当然卷积神经网络</p>
<p>07:30 CNN也只是神经网络结构中的一种</p>
<p>07:33 而且呢它有一个致命的局限性</p>
<p>07:35 就是它主要用于静态数据</p>
<p>07:37 比如说图片</p>
<p>07:38 那么如果我们要处理的是时间序列</p>
<p>07:41 文本</p>
<p>07:41 语音视频等动态数据</p>
<p>07:43 就需要引入另外一种神经网络结构了</p>
<p>07:46 它可以说是现在我们大语言模型的鼻祖了</p>
<p>07:50 好我们用了四个视频的内容</p>
<p>07:52 终于把前面所需要铺垫的知识</p>
<p>07:55 从头到尾给推出来了</p>
<p>07:56 那下个视频开始</p>
<p>07:58 我们就可以坐着我们这几个视频搭载的火箭</p>
<p>08:01 冲刺到现代AI技术的最前沿</p>
<p>08:03 请大家做好战斗准备吧</p>
<h2 id="从词嵌入到-RNN"><a href="#从词嵌入到-RNN" class="headerlink" title="从词嵌入到 RNN"></a>从词嵌入到 RNN</h2><p>00:00 给你几个字</p>
<p>00:00 让你生成下一个字</p>
<p>00:02 给你一句话</p>
<p>00:03 让你判断每个词的褒贬</p>
<p>00:05 如果把这些设计成一个神经网络的函数</p>
<p>00:07 来实现这个功能</p>
<p>00:09 你该怎么做呢</p>
<p>00:10 先别急</p>
<p>00:11 要想把这些文字作为输入参数</p>
<p>00:13 首先得把这些文字变成计算机能够识别的数字</p>
<p>00:17 这个过程就叫做编码</p>
<p>00:19 那具体怎么编码呢</p>
<p>00:21 有两种极端的方式</p>
<p>00:23 一种是只用一个数字标识来代表每个词</p>
<p>00:26 比如一代表我</p>
<p>00:27 二代表你3568代表地球等等</p>
<p>00:31 你的词表有多大</p>
<p>00:32 数字标识的范围就要有多大</p>
<p>00:35 这样的缺点非常明显</p>
<p>00:36 就是维度太低了</p>
<p>00:38 相当于一个一维的向量</p>
<p>00:40 而且数字标识本身对语言理解没有任何意义</p>
<p>00:43 无法灵活地衡量词和词之间的相关性</p>
<p>00:47 但另一种极端的方式是</p>
<p>00:48 准备一个超级超级大的向量</p>
<p>00:51 每个词只有向量中一个位置是一</p>
<p>00:54 剩下的都是零</p>
<p>00:55 这种编码方式叫做one hot</p>
<p>00:57 翻译过来叫独热编码</p>
<p>01:00 one hot的缺点也非常明显</p>
<p>01:02 就是维度太高了</p>
<p>01:03 而且非常稀疏</p>
<p>01:05 假如此表中有10万个词</p>
<p>01:07 那么这就是一个10万维度的向量</p>
<p>01:10 而且每个向量之间都是正交的</p>
<p>01:12 所以词和词之间仍然无法找到相关性</p>
<p>01:15 那如果把向量中每个位置都看作一个特征的话</p>
<p>01:19 这里就相当于每个特征都是非常死板的</p>
<p>01:22 是或者否维度太高不好</p>
<p>01:24 维度太低也不好</p>
<p>01:26 那简单了</p>
<p>01:27 弄一个不高不低的就好喽</p>
<p>01:28 这种方式就叫做此嵌入</p>
<p>01:31 通过磁嵌入的方式所得到的磁向量</p>
<p>01:35 维度不高也不低</p>
<p>01:36 每个位置数依然可以理解为某一个特征</p>
<p>01:39 只不过这是训练出来的</p>
<p>01:41 不是我们人定的</p>
<p>01:42 所以特征是什么</p>
<p>01:43 可能我们人类完全无法理解</p>
<p>01:46 那为什么这种方式可以表示词和词之间</p>
<p>01:49 语义上的相关性呢</p>
<p>01:50 我们可以用两个向量的点击或余弦相似度</p>
<p>01:54 来表示向量之间的相关性</p>
<p>01:56 进而表示两个词语之间的相关性</p>
<p>01:59 这就将自然语言之间的联系</p>
<p>02:02 转化为了可以用数学公式计算出来的方式</p>
<p>02:05 很关键</p>
<p>02:06 同时一些数学上的计算结果</p>
<p>02:08 也能反映出一些现实中很神奇的解释</p>
<p>02:11 比如一个训练好的词嵌入矩阵</p>
<p>02:14 可能会使得桌子减去椅子</p>
<p>02:16 等于鼠标减去键盘</p>
<p>02:18 你可以暂停下来</p>
<p>02:20 体会一下这里面蕴含的有趣的深意</p>
<p>02:24 把所有词向量组成了一个大矩阵</p>
<p>02:27 这个大的矩阵就叫做嵌入矩阵</p>
<p>02:29 这里的每一列就表示一个词向量</p>
<p>02:32 像刚刚说的这个矩阵</p>
<p>02:35 不是我们人类手动给每个词赋值而形成的</p>
<p>02:38 是通过深度学习的方法训练出来的</p>
<p>02:41 比如比较经典的方式就是word to back</p>
<p>02:43 这里就不展开讲解了</p>
<p>02:45 你就当做已经有了一个这样的嵌入矩阵</p>
<p>02:48 每一个可能的词语</p>
<p>02:50 都可以从这里找到对应的词向量</p>
<p>02:53 这些磁向量的维度非常高</p>
<p>02:55 所以它所在的空间的维度也非常高</p>
<p>02:58 这个空间就叫做前空间</p>
<p>03:00 我们人类对二维空间很好理解</p>
<p>03:03 最多到三维空间也还行</p>
<p>03:05 再往上就想象不出来了</p>
<p>03:07 那么这些词在高维前空间中的相对位置关系</p>
<p>03:11 虽然可以通过点击或余弦相似度算出来</p>
<p>03:14 但最好有一种直观的方式</p>
<p>03:16 能让我们亲眼可视化的看到</p>
<p>03:18 哪怕不那么准确也行</p>
<p>03:20 于是便有了一些方法</p>
<p>03:22 将这个前空间降维</p>
<p>03:24 投影到二维或三维的坐标系中</p>
<p>03:27 来直观的可视化不同词语之间的距离</p>
<p>03:30 还是非常有趣的</p>
<p>03:32 好了</p>
<p>03:33 有关词嵌入和嵌入矩阵</p>
<p>03:36 我们就先聊到这里</p>
<p>03:37 这时每个词都可以编码成向量</p>
<p>03:40 然后送到神经网络输入端的神经元中了</p>
<p>03:43 我们再来看看最初的需求</p>
<p>03:45 输入一句话</p>
<p>03:46 输出每个单词的褒贬性</p>
<p>03:49 这里有123455个词</p>
<p>03:51 通过词嵌入</p>
<p>03:52 把每个词变成一个300维的词向量</p>
<p>03:55 那么输入端就要一共有1500个神经元</p>
<p>03:59 这样行不行呢</p>
<p>04:00 当然可以</p>
<p>04:01 但是有两个问题</p>
<p>04:02 一个是输入层太大了</p>
<p>04:04 而且会随着一句话中词语数量多少而变化</p>
<p>04:08 是变长的</p>
<p>04:09 不确定的</p>
<p>04:10 另一个是无法体现词语的先后顺序</p>
<p>04:13 仅仅是把它们非常生硬的平铺展开</p>
<p>04:16 成了一个非常大的向量</p>
<p>04:17 一股脑地送入了输入层</p>
<p>04:19 这就好比我们之前说的图像识别领域</p>
<p>04:22 把一张图片的所有像素点展开成一个大向量</p>
<p>04:25 一股脑地送入输入层</p>
<p>04:27 一个道理</p>
<p>04:27 这样既增加了神经元的个数</p>
<p>04:29 又不能很好地抽象出特征和关联</p>
<p>04:32 有点费力不讨好</p>
<p>04:34 那在CNN中</p>
<p>04:35 我们是通过卷积操作提取了图像的特征</p>
<p>04:38 那么在自然语言处理领域</p>
<p>04:40 我们可以通过什么办法</p>
<p>04:41 既能解决词语之间的先后顺序问题</p>
<p>04:44 又能降低输入层的参数量呢</p>
<p>04:47 首先我们还是用经典的神经网络</p>
<p>04:50 但不要输入一句话</p>
<p>04:52 而是输入一个词</p>
<p>04:53 输出就是这个词是褒义还是贬义</p>
<p>04:56 当然这里的字母都表示矩阵就不再赘述了</p>
<p>04:59 这时假设第二个词来了</p>
<p>05:01 也是经过一样的神经网络很简单</p>
<p>05:04 那此时我们用尖括号表示是第几个词</p>
<p>05:07 这样就有了顺序关系</p>
<p>05:09 那现在的问题是</p>
<p>05:11 第二个词的计算过程</p>
<p>05:12 完全没有让第一个词的任何信息参与进来</p>
<p>05:16 那这该怎么办呢</p>
<p>05:17 答案已经写在脸上了</p>
<p>05:19 那就让他参与进来就好喽</p>
<p>05:21 那可以这样</p>
<p>05:22 我们让第一个词经过非线性变换后</p>
<p>05:25 别急着直接输出</p>
<p>05:27 结果先输出到一个隐藏状态H1</p>
<p>05:30 然后再经过一次非线性变换得到输出Y1</p>
<p>05:34 接下来这个隐藏状态H1的值和第二个词X2</p>
<p>05:39 一起参与运算</p>
<p>05:41 那同理对第二个词的流程也是一样</p>
<p>05:44 先输出一个隐藏状态H2</p>
<p>05:46 然后继续往下传递</p>
<p>05:48 那这样的话呢</p>
<p>05:50 前面的词的信息就这样不断的往下传递</p>
<p>05:53 直到传到最后一句话的最后一个词那里</p>
<p>05:56 这样就把一句话中</p>
<p>05:58 所有的词的信息都囊括进来了</p>
<p>06:01 当然这里的W就要有所区分了</p>
<p>06:03 有专门针对磁向量的WXH矩阵</p>
<p>06:07 有专门针对隐藏状态的WHH矩阵</p>
<p>06:10 以及最终计算输出结果的WHY矩阵</p>
<p>06:14 那同样对于偏执向B也是如此</p>
<p>06:17 把这个图简化一下</p>
<p>06:18 那这就是循环神经网络RNN</p>
<p>06:23 当然啦还会有个图这样画</p>
<p>06:26 那这个RN模型就具备了理解词和词之间</p>
<p>06:30 先后顺序的能力</p>
<p>06:32 那这样就可以解决</p>
<p>06:33 判断一句话中各个单词的褒贬词性</p>
<p>06:36 给出一句话</p>
<p>06:37 不断生成下一个字</p>
<p>06:39 以及翻译等多种自然语言处理的工作了</p>
<p>06:43 那如果你还有些懵的话</p>
<p>06:45 我们再把矩阵展开来看看</p>
<p>06:48 首先第一个词X1和权重矩阵WXH相乘</p>
<p>06:53 得到第一个词的隐藏状态</p>
<p>06:55 H1准备往后传</p>
<p>06:57 H1和权重矩阵WHY相乘</p>
<p>07:00 得到第一个词的输出结果</p>
<p>07:02 Y1这时候计算第二个词</p>
<p>07:05 同样要和权重矩阵WXH相乘</p>
<p>07:08 但注意这个时候要把第一个词的隐藏状态</p>
<p>07:12 加到输入向量里拼接起来</p>
<p>07:15 同时权重矩阵也增加一个WHH</p>
<p>07:18 最终计算出第二个词的隐藏状态</p>
<p>07:21 H2准备继续往后传</p>
<p>07:23 那后面的流程就一样了</p>
<p>07:47 最后看一下公式</p>
<p>07:48 其实非常简单</p>
<p>07:49 和经典的神经网络相比</p>
<p>07:51 就是多了一个前一时刻的隐藏状态而已</p>
<p>07:58 回顾一下</p>
<p>07:59 其实本期的内容非常简单</p>
<p>08:01 我们想处理自然语言的一系列问题</p>
<p>08:03 首先就要把词转换成计算机能够识别的数字</p>
<p>08:07 这个过程叫编码</p>
<p>08:09 通过编码词而形成的向量叫做磁向量</p>
<p>08:12 编码词向量有多种方式</p>
<p>08:14 其中一种是准备一个词表大小的向量</p>
<p>08:17 只有一个位置是一</p>
<p>08:19 这种方式叫做one hot及独热编码</p>
<p>08:22 这种编码方式维度太高</p>
<p>08:24 词之间缺乏相关性</p>
<p>08:26 所以另一种更有效的方式叫做词嵌入</p>
<p>08:29 词嵌入所需要经过训练而得到的矩阵</p>
<p>08:33 叫做嵌入矩阵</p>
<p>08:38 磁向量之间的相关性</p>
<p>08:39 可以用点击或余弦相似度来计算</p>
<p>08:42 有了磁向量之后</p>
<p>08:44 就可以输入到神经网络进行各种训练了</p>
<p>08:47 经典的神经网络无法表达词的先后顺序</p>
<p>08:50 因此我们增加了一个隐藏状态</p>
<p>08:52 在词和词之间传递不同的词</p>
<p>08:55 使用不同的时间步T来表示</p>
<p>08:57 那这个不同于经典神经网络的结构</p>
<p>09:00 就叫做循环神经网络RNN</p>
<p>09:04 当然RNN还有两个非常严重的问题</p>
<p>09:08 一信息会随着时间步的增多而逐渐丢失</p>
<p>09:11 无法捕捉长期依赖</p>
<p>09:13 而有的语句恰恰是距离很远的地方</p>
<p>09:16 起到了关键性的作用</p>
<p>09:17 2RN必须按顺序处理</p>
<p>09:20 每个时间步依赖上一个时间步的隐藏状态</p>
<p>09:23 的计算结果</p>
<p>09:25 那为了解决这些问题</p>
<p>09:26 人们使用GRU和LSTM改进了传统的RN</p>
<p>09:31 但是这些仍然是建立在让信息一点一点</p>
<p>09:34 按照时间簿传递的思路来解决</p>
<p>09:36 只能缓解而无法根治</p>
<p>09:39 那我们是否有一种可以彻底抛弃这种顺序计算</p>
<p>09:42 直接一眼把全部信息尽收眼底的新方案呢</p>
<p>09:47 有的那就是transformer</p>
<h2 id="简单而强大的-Transformer"><a href="#简单而强大的-Transformer" class="headerlink" title="简单而强大的 Transformer"></a>简单而强大的 Transformer</h2><p>00:00 用神经网络做个翻译任务</p>
<p>00:01 我爱你</p>
<p>00:02 宝贝</p>
<p>00:02 我爱你</p>
<p>00:03 宝贝儿</p>
<p>00:04 先用词嵌入的方式把每个词转换成一个词向量</p>
<p>00:07 简单点</p>
<p>00:08 假设维度就是六</p>
<p>00:09 如果把每个词直接丢到一个全连接神经网络中</p>
<p>00:12 那每个词都没有上下文的信息</p>
<p>00:15 且长度只能一一对应</p>
<p>00:16 不太行</p>
<p>00:17 如果用循环神经网络RNN又面临串行计算</p>
<p>00:21 而且如果句子太长</p>
<p>00:22 也会导致长期依赖困难的问题也不太行</p>
<p>00:26 那这也不行</p>
<p>00:27 那也不行</p>
<p>00:27 可咋整呢</p>
<p>00:28 小孩子才做选择</p>
<p>00:29 成年人全都不要直接发明一个全新的方案</p>
<p>00:33 跟我走</p>
<p>00:34 首先我们给每个词一个位置编码</p>
<p>00:36 表示这个词出现在整个句子中的位置</p>
<p>00:39 具体怎么计算</p>
<p>00:40 再说把位置编码加到原来的词向量里</p>
<p>00:43 现在这个词就有了位置信息</p>
<p>00:46 但此时每个词还没有其他词的上下文信息</p>
<p>00:50 也就是注意不到其他词的存在</p>
<p>00:52 那怎么办呢</p>
<p>00:53 接着看</p>
<p>00:54 别眨眼</p>
<p>00:55 首先我们用一个WQ矩阵和第一个词向量相乘</p>
<p>00:59 得到维度不变的Q1向量</p>
<p>01:01 这里的WQ矩阵是可以通过训练过程学习的</p>
<p>01:05 一组权重值</p>
<p>01:06 同理我们用wk矩阵和第一个词向量相乘</p>
<p>01:10 得到K1</p>
<p>01:11 再用WV矩阵得到V1</p>
<p>01:14 接着对其他词向量也和相同的WQ</p>
<p>01:18 KV矩阵相乘</p>
<p>01:19 分别得到自己对应的QKV向量</p>
<p>01:22 当然实际在计算机GPU中运算的时候</p>
<p>01:25 是通过拼接而成的大矩阵做乘法</p>
<p>01:28 并不是像我们刚刚那样一步一步计算的</p>
<p>01:31 得到的直接就是包含所有词向量的QKV矩阵</p>
<p>01:35 不过为了理解</p>
<p>01:36 我们解释的时候还是拆成一个个的词向量</p>
<p>01:39 现在原来的磁向量已经分别通过线性变换</p>
<p>01:42 映射成了QKV维度</p>
<p>01:45 和原来是一样的</p>
<p>01:46 接下来我们让Q1和K2做点击</p>
<p>01:50 这表示在第一个词的视角里</p>
<p>01:52 第一个词和第二个词的相似度是多少</p>
<p>01:56 同理依次和K3做点击</p>
<p>01:58 表示和第三个词的相似度</p>
<p>02:01 和K4做点击</p>
<p>02:02 表示和第四个词的相似度</p>
<p>02:04 最后呢也补上一个和自己做点击</p>
<p>02:07 表示和自己的相似度</p>
<p>02:09 那拿到这些相似度的系数后</p>
<p>02:12 分别和V向量相乘</p>
<p>02:14 再相加得到A1</p>
<p>02:16 那此时这个A1就表示在第一个词的视角下</p>
<p>02:21 按照和它相似度大小</p>
<p>02:23 按权重把每个词的词向量都加到了一块儿</p>
<p>02:26 那这就把全部上下文的信息</p>
<p>02:29 都包含在第一个词当中了</p>
<p>02:31 而且是用第一个词的视角来看的</p>
<p>02:34 同理其他几个词也按照这种方式</p>
<p>02:37 那么此时每个词都把其他词的词向量</p>
<p>02:42 按照和自己的相似度</p>
<p>02:43 权重加到了自己的词向量中</p>
<p>02:46 好那这里的什么QKV都是中间的计算过程了</p>
<p>02:50 我们从全局视角看</p>
<p>02:52 现在就是把最初的输入的词向量经过一番处理</p>
<p>02:56 变成了一组新的词向量</p>
<p>02:58 不一样的是呢</p>
<p>02:59 这组新的词向量中</p>
<p>03:00 每一个都是包含了位置信息和其他词</p>
<p>03:04 上下文信息的一组新的词向量</p>
<p>03:06 这就是注意力机制</p>
<p>03:08 attention做的事情</p>
<p>03:12 我们再进一步优化下</p>
<p>03:13 有的时候一个词和另一个词的关系</p>
<p>03:16 可能从不同的视角看是不一样的</p>
<p>03:19 对于注意力机制来说</p>
<p>03:21 如果只通过一种方式计算一次相关性</p>
<p>03:24 灵活性就会大大降低</p>
<p>03:26 所以我们做些改进</p>
<p>03:27 之前我们是每个词计算一组QKV</p>
<p>03:30 现在我们在这个QQV基础上</p>
<p>03:32 再经过两个权重矩阵变成两组QKV</p>
<p>03:36 给每个词两个学习机会</p>
<p>03:38 学习到不同的</p>
<p>03:39 要计算相似度QQV来增加语言的灵活性</p>
<p>03:43 这里的每组QKV成为一个头</p>
<p>03:46 接下来在每个头里面的QQV</p>
<p>03:49 仍然经过刚刚的注意力层的运算</p>
<p>03:52 得到A向量</p>
<p>03:53 然后把两个A向量拼接起来</p>
<p>03:55 得到了和刚刚一样的结构</p>
<p>03:58 而对于刚刚的注意力机制attention</p>
<p>04:00 这种方式就叫做多头注意力</p>
<p>04:02 多头注意力</p>
<p>04:04 而我们刚刚举的例子就是两个头的情况好</p>
<p>04:09 那我现在要恭喜你</p>
<p>04:11 已经把transformer架构</p>
<p>04:12 最核心的逻辑都搞清楚了</p>
<p>04:14 你信不信不信的话</p>
<p>04:16 我们对照一下transformer的经典论文</p>
<p>04:18 中的架构图来看看</p>
<p>04:19 首先第一步就是把输入的内容</p>
<p>04:22 通过词嵌入的方式转换成磁向量矩阵</p>
<p>04:25 对应的就是这里</p>
<p>04:27 第二步加入位置信息</p>
<p>04:29 其实就是再加个形状一样的矩阵</p>
<p>04:31 对应的就是这里</p>
<p>04:33 第三步经过多头注意力的处理</p>
<p>04:36 输出的矩阵维度和输入没有变化</p>
<p>04:38 给每个词向量增加了上下文信息</p>
<p>04:41 对应的就是这里</p>
<p>04:42 后面还有一步添加了残差网络和归一化处理</p>
<p>04:46 是为了解决梯度消失</p>
<p>04:48 并且让分布更加稳定而做的优化</p>
<p>04:50 我们刚刚没有展开这块儿</p>
<p>04:52 那对应的就是这里</p>
<p>04:54 同时我们也可以看到</p>
<p>04:55 整个transformer的标准架构中</p>
<p>04:57 最主要的就是多头注意力的处理</p>
<p>05:00 相当于我们把这些部分的逻辑都搞明白了</p>
<p>05:03 快给自己鼓鼓掌吧</p>
<p>05:08 下面深入到多头注意力机制的细节部分</p>
<p>05:11 我们再看看</p>
<p>05:12 如果是不分多头的单头注意力</p>
<p>05:15 那么就是先让Q和K相乘</p>
<p>05:17 得到一个相似度系数的一个矩阵</p>
<p>05:20 然后再和V相乘</p>
<p>05:21 最终得到了包含上下文信息的磁向量矩阵</p>
<p>05:26 当然我们上面的讲解过程呢</p>
<p>05:28 省略了中间的缩放掩码和一层soft max处理</p>
<p>05:32 再看右边的多头注意力情况</p>
<p>05:34 首先QKV分别经过线性变换</p>
<p>05:38 拆分成多组</p>
<p>05:39 相当于给了多次机会学习到不同的相似度关系</p>
<p>05:43 依次经过注意力机制运算后</p>
<p>05:45 把运算结果拼接起来</p>
<p>05:48 是不是完全一样呢</p>
<p>05:50 不过我们讲解的时候还省略了一次线性变换</p>
<p>05:53 即多头结果并不是简单的拼接起来</p>
<p>05:56 还需要再次经过一层权重矩阵的乘法</p>
<p>05:59 这时候再看两个核心公式就很好理解了</p>
<p>06:02 所谓注意力运算就是QK矩阵相乘经过缩放</p>
<p>06:07 在经过soft max层处理</p>
<p>06:09 最后和V相乘</p>
<p>06:12 对于多头情况</p>
<p>06:14 就是先将QKV矩阵</p>
<p>06:16 经过多个权重矩阵拆分到多个头中</p>
<p>06:19 分别经过注意力机制的运算</p>
<p>06:21 最后合并起来</p>
<p>06:22 再经过一次矩阵运算</p>
<p>06:24 得到了输出</p>
<p>06:26 再回过头来看一下这个全局的图</p>
<p>06:29 左边的部分叫做编码器</p>
<p>06:31 右边的部分叫做解码器</p>
<p>06:33 你实在不愿意叫也没关系</p>
<p>06:35 假设这个是用于翻译的任务</p>
<p>06:38 我们训练这个神经网络的过程是</p>
<p>06:40 首先输入要翻译的文本</p>
<p>06:42 我爱你，宝贝</p>
<p>06:44 然后经过词嵌入引入位置编码</p>
<p>06:47 经过多头注意力残差和归一化处理</p>
<p>06:50 接着送入一个全连接神经网络</p>
<p>06:53 再残差和归一化处理</p>
<p>06:55 结果送入解码器的一个多头注意力机制</p>
<p>06:58 的两个输入中</p>
<p>07:00 作为KV矩阵</p>
<p>07:01 再看右面解码器的部分输出是翻译后的文本</p>
<p>07:06 我爱你宝贝儿</p>
<p>07:07 同样经过此嵌入</p>
<p>07:09 引入位置编码</p>
<p>07:10 经过多头注意力</p>
<p>07:12 然后残差和归一化处理下</p>
<p>07:15 然后送入上面说的多头注意力的一个输入中</p>
<p>07:19 作为Q矩阵和刚刚从编码器中送入的KV矩阵</p>
<p>07:24 再经过多头注意力残差归一化</p>
<p>07:27 再全连接神经网络</p>
<p>07:29 再残差归一化</p>
<p>07:30 最后再经过一层线性变换的神经网络</p>
<p>07:34 投射到此表向量中</p>
<p>07:36 最后用soft max层转化为概率</p>
<p>07:39 这就代表预测的下一个词在词表中的概率分布</p>
<p>07:44 那我们取概率最高的就是下一个词应该是什么</p>
<p>07:48 这里有一个小的不同</p>
<p>07:50 就是有个掩码</p>
<p>07:51 这个掩码的作用是真正推理</p>
<p>07:54 翻译时是一个词一个词翻译的</p>
<p>07:56 比如说这个时候翻译到我下一个词应该是爱</p>
<p>08:00 所以输出我的时候是看不到后面的词的</p>
<p>08:04 这就需要掩码来把后面的词遮挡住</p>
<p>08:06 以便训练的时候模拟真实推理场景时的过程</p>
<p>08:10 比如当此时输入是i love you baby</p>
<p>08:13 输出只有一个词</p>
<p>08:14 我的时候经过这个神经网络</p>
<p>08:17 最后上方输出词表的概率分布</p>
<p>08:19 我们想要的结果就是I字的概率值最大</p>
<p>08:23 如果训练时有偏差</p>
<p>08:25 那么就计算损失函数</p>
<p>08:26 再反向传播</p>
<p>08:28 调整transformer结构中的各种权重矩阵</p>
<p>08:31 直到学习好为止</p>
<p>08:34 总的来说</p>
<p>08:34 transformer确实是个特别简单的架构</p>
<p>08:38 原文中也是这样说的</p>
<p>08:39 尤其是当你有了基础的神经网络知识之后</p>
<p>08:42 如果你看了这个系列之前的视频</p>
<p>08:45 那就只有多头注意力</p>
<p>08:46 这一层是陌生的</p>
<p>08:48 但是它其实拆解之后也是各种矩阵相乘呀</p>
<p>08:51 相加呀</p>
<p>08:51 这种操作罢了</p>
<p>08:52 那其余的词嵌入位置</p>
<p>08:55 编码残差归一化</p>
<p>08:56 经典神经网络</p>
<p>08:58 soft max层等等</p>
<p>08:59 都是我们之前的视频中已经了解过的概念</p>
<p>09:02 把这些老东西拼凑拼凑就诞生了</p>
<p>09:05 我们现在大模型技术的鼻祖transformer</p>
<p>09:09 那GBT的底层其实就是transform的一半</p>
<p>09:12 即只有解码器的部分</p>
<p>09:14 也不翻译</p>
<p>09:15 谁只管看前面的词</p>
<p>09:17 猜下一个词</p>
<p>09:18 别看他来回的猜词猜词</p>
<p>09:20 猜着猜着就变成了聊天写代码</p>
<p>09:23 解数学题的全能选手了</p>
<p>09:26 那transformer的架构来源于经典的论文</p>
<p>09:28 你只需要关注</p>
<p>09:30 本期视频的内容理解之后再去看这篇论文</p>
<p>09:33 你就会发现非常非常非常容易理解</p>
<p>09:36 因为它本身就是一个很简单的架构</p>
<p>09:39 也正因为简单粗暴</p>
<p>09:40 但是效果却出奇的好</p>
<p>09:42 所以才会广为流传</p>
<p>09:44 并成为现代大模型的基础</p>
<p>09:46 如果大家感兴趣</p>
<p>09:47 我可以专门出一期视频</p>
<p>09:49 从头到尾的讲解一下这篇论文</p>
<p>09:51 可以弹幕或评论区留下你的想法</p>
<p>09:53 当然啦</p>
<p>09:54 建议把这个系列之前的视频完整的看一遍</p>
<p>09:57 每期视频呢不到10分钟</p>
<p>09:59 但可以带着你从零开始真正理解神经网络</p>
<p>10:02 一步一步的发展脉络</p>
<p>10:04 加油吧</p>
<h2 id="速览大模型-99-词"><a href="#速览大模型-99-词" class="headerlink" title="速览大模型 99 词"></a>速览大模型 99 词</h2><p>00:00 万物皆函数</p>
<p>00:01 早期人们用符号主义的思想找到精确函数</p>
<p>00:04 试图解释一切原理</p>
<p>00:06 但遇到了瓶颈</p>
<p>00:07 后来人们转用连接主义思想</p>
<p>00:09 先啥都不管</p>
<p>00:10 弄一个非常复杂的函数</p>
<p>00:11 然后根据计算出的预测值与真实值的误差</p>
<p>00:14 不断调整里面的未知参数</p>
<p>00:17 这个函数叫做模型</p>
<p>00:19 模型里的参数叫做权重</p>
<p>00:21 如果模型中的参数量特别大</p>
<p>00:23 就叫做大模型</p>
<p>00:24 用于自然语言处理的大模型就叫做大语言模型</p>
<p>00:28 调整参数的过程就是模型的训练</p>
<p>00:31 事先训练好一个基础模型的方式叫做预训练</p>
<p>00:34 基于预训练的模型继续训练</p>
<p>00:36 让模型学会具体的任务的方式叫做微调参数</p>
<p>00:40 调整好后</p>
<p>00:41 根据函数的输入计算输出结果</p>
<p>00:43 这个过程叫做推理</p>
<p>00:45 这些概念在大模型时代到来之后</p>
<p>00:48 逐渐火热了起来</p>
<p>00:49 当模型参数量足够大的时候</p>
<p>00:51 对话能力有了质的提升</p>
<p>00:53 产生了一定程度的推理能力</p>
<p>00:55 这种量变引起质变</p>
<p>00:57 而突然出现的之前没有的能力的现象叫做涌现</p>
<p>01:01 大圆模型爆火的产品是2023年的chat gt</p>
<p>01:05 它是一款用于聊天的产品</p>
<p>01:07 而它背后使用的代言模型是GPT是个系列</p>
<p>01:11 开发这个模型的公司是OpenAI产品模型公司</p>
<p>01:15 这也是一开始很多人搞混淆的概念</p>
<p>01:18 而由于这家公司推出的产品</p>
<p>01:20 一直保持不开放源代码</p>
<p>01:22 也就是闭源</p>
<p>01:22 所以也正式更名为close AI括弧</p>
<p>01:25 开个玩笑</p>
<p>01:26 一个模型需要有训练它的代码</p>
<p>01:29 有了代码就可以训练出一组权重</p>
<p>01:31 有了权重就可以进行推理</p>
<p>01:33 也就是可以对外提供服务了</p>
<p>01:35 不开放源代码</p>
<p>01:37 也不开放权重</p>
<p>01:38 只对外提供服务的模型叫做闭源模型</p>
<p>01:41 如ChatGPT cloud germany y等开放模型</p>
<p>01:45 权重可以直接下载到自己电脑上</p>
<p>01:47 部署的模型叫做开源模型</p>
<p>01:49 但实际上大部分现在说的开源模型</p>
<p>01:52 只是开放了权重</p>
<p>01:53 而不开放训练代码和训练数据</p>
<p>01:56 所以准确说其实叫开放权重模型</p>
<p>01:59 比如最近爆火的deep seek以及划时代的lama等</p>
<p>02:02 不但开放了模型结构和权重</p>
<p>02:04 还开放了训练代码的模型</p>
<p>02:06 可以叫完全开源模型</p>
<p>02:08 比如说miss f</p>
<p>02:09 当然了</p>
<p>02:10 有了模型权重</p>
<p>02:11 其实就可以下载到本地进行部署</p>
<p>02:13 并且使用了</p>
<p>02:14 很少有人需要重新训练它</p>
<p>02:16 这个不依赖于他人的服务</p>
<p>02:18 而是把模型下载到本地进行使用的过程</p>
<p>02:21 叫做私有化部署</p>
<p>02:22 私有化部署依赖很多复杂的环境配置</p>
<p>02:25 就是需要装很多依赖的软件和工具包</p>
<p>02:28 而且需要性能较为强劲的GPU的支持</p>
<p>02:31 对于仅仅想尝鲜的个人</p>
<p>02:33 专门为此去买一台电脑不太合适</p>
<p>02:35 因此就有了云桌面的概念</p>
<p>02:37 你可以直接使用别人打包好的环境和软件</p>
<p>02:40 这个打包好的东西就叫做镜像</p>
<p>02:43 大语言模型的本质就是个大函数</p>
<p>02:45 根据前面的一句话</p>
<p>02:46 持续不断地计算下一个词是什么</p>
<p>02:49 这种基于输入内容</p>
<p>02:50 自动生成新内容的人工智能系统叫做生成式AI</p>
<p>02:54 当然除了文本</p>
<p>02:55 也包含图像</p>
<p>02:56 声</p>
<p>02:56 音视频等等</p>
<p>02:57 这里的每一个分割成最小力度的词叫做token</p>
<p>03:01 对话时所有给到大模型的信息叫做上下文</p>
<p>03:04 不同的模型有不同的上下文</p>
<p>03:06 长度限制越大</p>
<p>03:07 就越能记住前面的信息</p>
<p>03:08 上下文从另一个角度理解</p>
<p>03:10 也可以叫提示词</p>
<p>03:11 prompt可以指导模型的回答流程和风格</p>
<p>03:14 但其实就是个上下文而已</p>
<p>03:16 早期出现很多提示词工程师和提示词教程</p>
<p>03:19 其实本质就是教你怎么跟大模型说话而已</p>
<p>03:22 现在AI的对话越来越贴近人的方式了</p>
<p>03:25 所以你和人沟通起来有啥毛病</p>
<p>03:27 那么跟AI沟通也有啥毛病</p>
<p>03:29 你真正缺的是怎么表达清楚自己的意思</p>
<p>03:32 而不是prompt技巧</p>
<p>03:34 刚刚说了</p>
<p>03:35 大模型就是个大函数</p>
<p>03:36 函数是死的</p>
<p>03:37 所以根据前面的词输出的下一个词是固定的</p>
<p>03:40 但是我们可以一定程度的调整模型</p>
<p>03:43 输出的随机性</p>
<p>03:44 让下一个词的生成</p>
<p>03:45 并不总是取前面概率最高的那个词</p>
<p>03:48 控制输出的随机性的参数叫做温度控制范围</p>
<p>03:51 从概率最高的cake词中选择叫做top k</p>
<p>03:55 随机性太高</p>
<p>03:56 模型容易胡说</p>
<p>03:57 八道太低又会过于保守</p>
<p>03:59 也可能说错</p>
<p>03:59 这种在语言上说得通</p>
<p>04:01 但是在事实上狗屁不通</p>
<p>04:03 甚至虚假信息的现象叫做大模型的幻觉</p>
<p>04:06 为了解决幻觉问题</p>
<p>04:07 大模型或者一些套壳产品提供了联网能力</p>
<p>04:11 其实呢就是在大模型回答问题前</p>
<p>04:13 先去互联网上查找一些相关信息</p>
<p>04:16 把这些信息和你的问题拼接在一起</p>
<p>04:18 共同先发给大模型</p>
<p>04:20 然后进行回答</p>
<p>04:21 相当于带着答案回答问题了</p>
<p>04:23 之前很多自媒体的震惊体</p>
<p>04:25 炸裂体</p>
<p>04:26 天塌体的文章说</p>
<p>04:27 大模型拥有联网能力是有了重大突破</p>
<p>04:30 人类就要完蛋了</p>
<p>04:31 那实际上呢就是这么个玩意儿</p>
<p>04:33 有些数据网络上可能查不到</p>
<p>04:35 或者企业的数据不方便公开地放在互联网上</p>
<p>04:38 希望大模型去这些私有的数据库中查找答案</p>
<p>04:42 这种方式叫做检索</p>
<p>04:43 增强生成RAG和联网的思路一样</p>
<p>04:46 也是先查资料再回答问题</p>
<p>04:49 只不过查询的内容不在互联网上</p>
<p>04:51 而是在有一个私有的数据库中</p>
<p>04:53 我们通常叫它知识库</p>
<p>04:55 为了让模型和知识库中的语义进行匹配</p>
<p>04:57 知识通常会以向量的形式存储在向量数据库中</p>
<p>05:01 把文字转换成磁向量的方式叫做词嵌入对比</p>
<p>05:05 词向量之间的相似度</p>
<p>05:06 已在知识库中找到相关问题的答案的方式</p>
<p>05:09 叫做向量检索</p>
<p>05:11 解决了大模型的幻觉问题后</p>
<p>05:13 AI就可以真正的介入生产和生活中了</p>
<p>05:15 在内容创作领域</p>
<p>05:17 传统的由专业机构如影视公司</p>
<p>05:19 媒体机构</p>
<p>05:20 权威专家等创作的内容叫做pg c</p>
<p>05:23 随着移动互联网时代的到来</p>
<p>05:25 和自媒体时代的到来</p>
<p>05:26 由普通用户</p>
<p>05:27 比如说我创作的内容叫做UGC</p>
<p>05:29 而在AI时代</p>
<p>05:31 由AI创作或辅助创作的内容叫做AIGC</p>
<p>05:34 比较正向的案例呢</p>
<p>05:36 就是内容公司通过AI</p>
<p>05:37 加快产出速度和提升内容质量</p>
<p>05:39 而比较反面的案例呢</p>
<p>05:41 就是很多人用AI洗稿并疯狂产出内容</p>
<p>05:44 污染互联网的内容生态</p>
<p>05:46 插一嘴</p>
<p>05:46 这里有个比较容易混淆的词叫AGI</p>
<p>05:49 它的意思是人们对于人工智能最终形态的畅想</p>
<p>05:53 及通用人工智能大模型借鉴发展</p>
<p>05:56 不单单能处理文本内容</p>
<p>05:57 也能处理图片</p>
<p>05:58 声音视频等多种形式的内容</p>
<p>06:01 这种处理多种模式内容的能力叫做多模态</p>
<p>06:04 有的时候呢我们需要多次使用大模型的能力</p>
<p>06:07 比如第一步将口播稿分段</p>
<p>06:09 第二步给每个段落写成一个文生图的提示词</p>
<p>06:12 第三步生成一张合适的图片</p>
<p>06:15 这种把多个步骤编排成一个流程的能力</p>
<p>06:17 叫做工作流</p>
<p>06:18 包括可以在页面上进行傻瓜操作</p>
<p>06:21 编排工作流的工具</p>
<p>06:22 比如扣子</p>
<p>06:23 以及用代码的方式编排工作流的框架</p>
<p>06:26 如long unchain</p>
<p>06:26 按照工作流封装大模型和一整套工具集</p>
<p>06:30 用于自动完成某一类复杂任务的程序</p>
<p>06:33 叫做一个智能体</p>
<p>06:34 多个智能体互相协作</p>
<p>06:36 完成更复杂的任务的程序叫做多智能体</p>
<p>06:39 chat gbt的插件系统</p>
<p>06:41 早期昙花一现的auto gbt</p>
<p>06:43 以及最近又昙花一现的minus都属于智能体</p>
<p>06:46 智能体</p>
<p>06:47 需要操作各种应用</p>
<p>06:48 比如打开浏览器上网</p>
<p>06:50 打开计算器进行算术</p>
<p>06:52 或者操作手机上的微信</p>
<p>06:53 发送一条信息等</p>
<p>06:55 实现托管</p>
<p>06:56 为了更方便操作外部数据源和工具</p>
<p>06:58 as throi公司于2024年底</p>
<p>07:00 为AI系统提供了一个标准化的接口</p>
<p>07:03 或者说协议叫做MC</p>
<p>07:05 给了AI一个操作外部世界的统一标准</p>
<p>07:08 而谷歌于2025年4月推出的另一个协议</p>
<p>07:11 用于agent和agent之间的通信</p>
<p>07:14 叫做a to a协议</p>
<p>07:15 至此大模型的生态开始百花齐放</p>
<p>07:18 未来的想象空间是无限的</p>
<p>07:20 别看这么多工作流啊</p>
<p>07:22 智能体啊</p>
<p>07:22 MCP等概念兴起</p>
<p>07:24 但其实都是老一套工程方面的事情</p>
<p>07:26 大模型本身的能力已经发展的快到极限了</p>
<p>07:30 一方面呢模型大小到了极限</p>
<p>07:32 一个顶级大语言</p>
<p>07:33 模型的训练成本已经超过1亿美元了</p>
<p>07:36 另一方面模型的能力也快到达了极限</p>
<p>07:39 前十名模型能力的差距</p>
<p>07:41 已经从两年前的12%</p>
<p>07:43 缩小到了25年年初的5.4%</p>
<p>07:45 前两名更是从4.9%</p>
<p>07:47 缩小到了0.7%</p>
<p>07:49 模型之间已经快拉不出差距了</p>
<p>07:51 正所谓边际收益递减</p>
<p>07:53 所以呢就开始卷其他方向寻找出路</p>
<p>07:56 比如让模型更小</p>
<p>07:57 以便减少成本和方便个人使用的模型压缩方法</p>
<p>08:01 包括把模型中的浮点数用更低精度表示</p>
<p>08:04 以减少显存和计算的量化</p>
<p>08:07 用参数量较大的大模型</p>
<p>08:09 指导参数量较小的小模型的蒸馏</p>
<p>08:11 删除模型中不重要的神经元</p>
<p>08:14 让模型更稀疏</p>
<p>08:15 以提高速度的减脂</p>
<p>08:17 用更低成本改善微调方式的方法</p>
<p>08:20 如laura klaura adapter等</p>
<p>08:22 从推理能力方向增强模型能力的方式</p>
<p>08:25 如思维链</p>
<p>08:26 通过人类反馈的强化学习</p>
<p>08:28 让模型说的话更合人的心意的方法叫RLHF</p>
<p>08:33 当然啥方向都卷不动的时候</p>
<p>08:35 铁还可以封装现有的大模型接口</p>
<p>08:38 并对外提供服务</p>
<p>08:39 通俗的说法呢就是套壳或者提供AI工具</p>
<p>08:42 AI服务</p>
<p>08:43 AI课程</p>
<p>08:44 AI社区等</p>
<p>08:45 帮助别人开发和使用AI能力的周边产品</p>
<p>08:48 这种在AI淘金热里帮助别人淘金</p>
<p>08:51 来赚取金币的方式叫做卖铲子</p>
<p>08:54 可别看不上卖铲子的</p>
<p>08:55 这可是要对AI各领域的产品和生态</p>
<p>08:58 都了如指掌才行</p>
<p>09:00 和文字相关的就是自然语言处理</p>
<p>09:02 有名的包括刚刚说的chat gbt以及cloud Gemini</p>
<p>09:07 Deep sick</p>
<p>09:08 豆包同1000问腾讯元宝等</p>
<p>09:11 和图片相关的是计算机视觉</p>
<p>09:14 包括很多AI绘画的应用</p>
<p>09:16 比如闭源的mid journey</p>
<p>09:18 开源的stable diffusion</p>
<p>09:19 绘画工作流软件CONFEUI等</p>
<p>09:22 和语音相关的</p>
<p>09:24 包括文字转语音的TTS和</p>
<p>09:27 语音转文字的AS2</p>
<p>09:29 和视频相关的包括SORA</p>
<p>09:31 可灵及梦等AI视频生成应用</p>
<p>09:34 以及各种数字人应用等</p>
<p>09:36 除了帮助普通用户外</p>
<p>09:38 你还可以帮助开发者更好地使用AI</p>
<p>09:41 包括像英伟达一样提供好的显卡</p>
<p>09:44 也就是GPU以及配套的开发框架KA</p>
<p>09:47 或者提供专门针对人工智能的处理器</p>
<p>09:50 比如专门用于大规模神经网络训练与推理的</p>
<p>09:54 TPU和专门用于终端设备推理的AI加速芯片</p>
<p>09:58 NPU等软件方面</p>
<p>10:00 你可以提供适合AI的编程语言</p>
<p>10:02 Python提供针对AI编程的库</p>
<p>10:05 Pytorch tensorflow</p>
<p>10:06 建设AI开源平台和社区</p>
<p>10:09 Hugging face</p>
<p>10:09 方便开发者本地运行大模型的工具</p>
<p>10:12 欧拉马</p>
<p>10:13 提升大语言模型推理速度的推理引擎</p>
<p>10:16 VLMAI编程助手</p>
<p>10:18 包括单独以软件形式存在的cursor</p>
<p>10:21 或者以插件形式存在的GITHUBCOPD的等等等等</p>
<p>10:24 太多可以做的事情了</p>
<p>10:26 如果你认为还有哪些特别重要的没有提到</p>
<p>10:29 可以评论区或弹幕区帮我补充上</p>
<p>10:32 AI时代瞬息万变</p>
<p>10:33 产品工具层出不穷</p>
<p>10:35 但他的技术底座依然保持不变</p>
<p>10:38 从最底层的线性代数</p>
<p>10:40 微积分</p>
<p>10:41 概率论</p>
<p>10:42 最优化等数学知识</p>
<p>10:43 到深度学习中</p>
<p>10:45 用神经网络表示函数</p>
<p>10:46 用损失函数最小化为目标</p>
<p>10:49 通过反向传播训练参数</p>
<p>10:51 再到后面的经典神经网络结构</p>
<p>10:53 MLP用于图像数据处理的卷积神经网络</p>
<p>10:57 CNN用于序列数据处理的循环神经网络</p>
<p>11:00 Rn</p>
<p>11:01 以及引爆整个大模型时代的attention机制</p>
<p>11:04 和基于attention机制发明的transformer架构</p>
<p>11:08 他们共同撑起了现代AI技术的大厦</p>
<p>11:13 恭喜你</p>
<p>11:14 坚持到了现在</p>
<p>11:15 你已经超过了99%的人了</p>

              <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-6466750810172767"
     crossorigin="anonymous"></script>
<!-- 咖啡 -->
<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-6466750810172767"
     data-ad-slot="9259278386"
     data-ad-format="auto"
     data-full-width-responsive="true"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>
                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>AI大模型学习</div>
      <div>https://www.zhengcookie.site/zhengcookie/AI大模型学习/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>作者</div>
          <div>zhengcookie</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>发布于</div>
          <div>2025年12月24日</div>
        </div>
      
      
      
        <div class="license-meta-item">
          <div>许可协议</div>
          <div>
            
              
              
                <a class="print-no-link" target="_blank" href="https://creativecommons.org/licenses/by/4.0/">
                  <span class="hint--top hint--rounded" aria-label="BY - 署名">
                    <i class="iconfont icon-cc-by"></i>
                  </span>
                </a>
              
            
          </div>
        </div>
      
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/zhengcookie/ai%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%94%B5%E5%AD%90%E4%B9%A6/" title="ai大模型电子书">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">ai大模型电子书</span>
                        <span class="visible-mobile">上一篇</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/zhengcookie/agi%E5%A4%A7%E6%A8%A1%E5%9E%8B/" title="agi大模型">
                        <span class="hidden-mobile">agi大模型</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
  
  
    <article id="comments" lazyload>
      
  <div id="valine"></div>
  <script type="text/javascript">
    Fluid.utils.loadComments('#valine', function() {
      Fluid.utils.createScript('https://lib.baomitu.com/valine/1.5.1/Valine.min.js', function() {
        var options = Object.assign(
          {"appId":"sTZBx4mwQ0t3yfqJB5XmuIhz-gzGzoHsz","appKey":"KJPXk2hOqDfll4hbw93yYmUc","path":"window.location.pathname","placeholder":"请在这里写下你的评论","avatar":"/img/avatar.png","meta":["nick","mail","link"],"requiredFields":[],"pageSize":10,"lang":"zh-CN","highlight":false,"recordIP":false,"serverURLs":"","emojiCDN":null,"emojiMaps":null,"enableQQ":false,"bg":null,"visitor":false,"option":null},
          {
            el: "#valine",
            path: window.location.pathname
          }
        )
        new Valine(options);
        Fluid.utils.waitElementVisible('#valine .vcontent', () => {
          var imgSelector = '#valine .vcontent img:not(.vemoji)';
          Fluid.plugins.imageCaption(imgSelector);
          Fluid.plugins.fancyBox(imgSelector);
        })
      });
    });
  </script>
  <noscript>Please enable JavaScript to view the comments</noscript>


    </article>
  


          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header">
    <i class="iconfont icon-list"></i>
    <span>目录</span>
  </p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  







    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
    </div>
  
  
    <div class="statistics">
  
  

  
    
      <span id="leancloud-site-pv-container" style="display: none">
        总访问量 
        <span id="leancloud-site-pv"></span>
         次
      </span>
    
    
      <span id="leancloud-site-uv-container" style="display: none">
        总访客数 
        <span id="leancloud-site-uv"></span>
         人
      </span>
    
    

  

</div>

  
  
</div>

<!-- ================= 全站背景音乐（不要放到 if 里） ================= -->
<div id="bgm-player"></div>

<meting-js
  server="netease"
  type="playlist"
  id="17567727297"
  fixed="true"
  mini="true"
  autoplay="false"
  loop="all"
  order="random"
  preload="auto"
  volume="0.6"
  mutex="true">
</meting-js>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.4/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script src="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/meting@2/dist/Meting.min.js"></script>

<script  src="/js/events.js" ></script>~
<script  src="/js/plugins.js" ></script>


  <script  src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>




  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.20.1/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init(Object.assign({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      scrollSmooth    : true,
      includeTitleTags: true,
      headingsOffset  : -boardTop,
    }, CONFIG.toc));
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }

    Fluid.events.registerRefreshCallback(function() {
      if ('tocbot' in window) {
        tocbot.refresh();
        var toc = jQuery('#toc');
        if (toc.length === 0 || !tocbot) {
          return;
        }
        if (toc.find('.toc-list-item').length > 0) {
          toc.css('visibility', 'visible');
        }
      }
    });
  });
</script>


  <script src=https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/5.0.0/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));

    Fluid.events.registerRefreshCallback(function() {
      if ('anchors' in window) {
        anchors.removeAll();
        var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
        var res = [];
        for (var item of el) {
          res.push('.markdown-body > ' + item.trim());
        }
        if (CONFIG.anchorjs.placement === 'left') {
          anchors.options.class = 'anchorjs-link-left';
        }
        anchors.add(res.join(', '));
      }
    });
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  <script defer src="/js/leancloud.js" ></script>

  <script  src="/js/local-search.js" ></script>




  
<script src="/js/bgm-fix.js"></script>
<script src="//cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.js"></script>
<script src="//cdn.jsdelivr.net/gh/metowolf/MetingJS@1.2/dist/Meting.min.js"></script>



<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div>
  </noscript>
</body>
</html>
